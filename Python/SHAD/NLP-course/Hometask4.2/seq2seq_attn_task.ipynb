{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2seq models and attention\n",
    "\n",
    "This time we'll solve a problem of transribing hebrew words in english, also known as g2p (grapheme2phoneme)\n",
    "\n",
    " * word (sequence of letters in source language) -> translation (sequence of letters in target language)\n",
    "\n",
    "\n",
    "### About the task\n",
    "\n",
    "One notable property of Hebrew is that it's consonant language. That is, there are no wovels in the written language. One could represent wovels with diacritics above consonants, but you don't expect people to do that in everyay life.\n",
    "\n",
    "Therefore, some hebrew characters will correspond to several english letters and others - to none, so we should use encoder-decoder architecture to figure that out.\n",
    "\n",
    "![img](https://esciencegroup.files.wordpress.com/2016/03/seq2seq.jpg)\n",
    "_(img: esciencegroup.files.wordpress.com)_\n",
    "\n",
    "Encoder-decoder architectures are about converting anything to anything, including\n",
    " * Machine translation and spoken dialogue systems\n",
    " * [Image captioning](http://mscoco.org/dataset/#captions-challenge2015) and [image2latex](https://openai.com/requests-for-research/#im2latex) (convolutional encoder, recurrent decoder)\n",
    " * Generating [images by captions](https://arxiv.org/abs/1511.02793) (recurrent encoder, convolutional decoder)\n",
    " * Grapheme2phoneme - convert words to transcripts\n",
    "  \n",
    "We chose simplified __Hebrew->English__ machine translation for words and short phrases (character-level), as it is relatively quick to train even without a gpu cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EASY_MODE = True        #If True, only translates phrases shorter than 20 characters (way easier).\n",
    "                        #Useful for initial coding.\n",
    "                        #If false, works with all phrases (please switch to this mode for homework assignment)\n",
    "\n",
    "MODE = \"he-to-en\"                                #way we translate. Either \"he-to-en\" or \"en-to-he\"\n",
    "MAX_OUTPUT_LENGTH = 50 if not EASY_MODE else 20  #maximal length of _generated_ output, does not affect training\n",
    "REPORT_FREQ       = 100                          #how often to evaluate validation score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: preprocessing\n",
    "\n",
    "We shall store dataset as a dictionary\n",
    "`{ word1:[translation1,translation2,...], word2:[...],...}`.\n",
    "\n",
    "This is mostly due to the fact that many words have several correct translations.\n",
    "\n",
    "We have implemented this thing for you so that you can focus on more interesting parts.\n",
    "\n",
    "\n",
    "__Attention python2 users!__ You may want to cast everything to unicode later during homework phase, just make sure you do it _everywhere_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size =  130113\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "word_to_translation = defaultdict(list) #our dictionary\n",
    "\n",
    "bos = '_'\n",
    "eos = ';'\n",
    "\n",
    "with open(\"main_dataset.txt\") as fin:\n",
    "    for line in fin:\n",
    "        \n",
    "        en,he = line[:-1].lower().replace(bos,' ').replace(eos,' ').split('\\t')\n",
    "        word,trans = (he,en) if MODE=='he-to-en' else (en,he)\n",
    "        \n",
    "        if len(word) < 3: continue\n",
    "        if EASY_MODE:\n",
    "            if max(len(word),len(trans))>20:\n",
    "                continue\n",
    "        \n",
    "        word_to_translation[word].append(trans)\n",
    "    \n",
    "print (\"size = \",len(word_to_translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all unique lines in source language\n",
    "all_words = np.array(list(word_to_translation.keys()))\n",
    "# get all unique lines in translation language\n",
    "all_translations = np.array([ts for all_ts in word_to_translation.values() for ts in all_ts])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the dataset\n",
    "\n",
    "We hold out 10% of all words to be used for validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_words,test_words = train_test_split(all_words,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building vocabularies\n",
    "\n",
    "We now need to build vocabularies that map strings to token ids and vice versa. We're gonna need these fellas when we feed training data into model or convert output matrices into english words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from voc import Vocab\n",
    "inp_voc = Vocab.from_lines(''.join(all_words), bos=bos, eos=eos, sep='')\n",
    "out_voc = Vocab.from_lines(''.join(all_translations), bos=bos, eos=eos, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines\n",
      "['ק.ו.ן' 'קטגוריה:הוואנה' 'יצחק ברנייס' 'זומבי' 'אמה קאניף']\n",
      "\n",
      "words to ids (0 = bos, 1 = eos):\n",
      "[[  0  59  63   7  63  91   1   1   1   1   1   1   1   1   1   1]\n",
      " [  0  59  92  69   7 173 111  13  46  13   7   7  57 163  13   1]\n",
      " [  0 111 134 149  59 117  45 173 163 111 111  34   1   1   1   1]\n",
      " [  0  74   7  80  45 111   1   1   1   1   1   1   1   1   1   1]\n",
      " [  0  57  80  13 117  59  57 163 111  14   1   1   1   1   1   1]]\n",
      "\n",
      "back to words\n",
      "['ק.ו.ן', 'קטגוריה:הוואנה', 'יצחק ברנייס', 'זומבי', 'אמה קאניף']\n"
     ]
    }
   ],
   "source": [
    "# Here's how you cast lines into ids and backwards.\n",
    "batch_lines = all_words[:5]\n",
    "batch_ids = inp_voc.to_matrix(batch_lines)\n",
    "batch_lines_restored = inp_voc.to_lines(batch_ids)\n",
    "\n",
    "print(\"lines\")\n",
    "print(batch_lines)\n",
    "print(\"\\nwords to ids (0 = bos, 1 = eos):\")\n",
    "print(batch_ids)\n",
    "print(\"\\nback to words\")\n",
    "print(batch_lines_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw word/translation length distributions to estimate the scope of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAEICAYAAACtc9bVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb1b66713c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=[8,4])\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"words\")\n",
    "plt.hist(list(map(len,all_words)),bins=20);\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('translations')\n",
    "plt.hist(list(map(len,all_translations)),bins=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: deploy encoder-decoder (2 points)\n",
    "\n",
    "__assignment starts here__\n",
    "\n",
    "Our architecture consists of two main blocks:\n",
    "* Encoder reads words character by character and outputs code vector (usually a function of last RNN state)\n",
    "* Decoder takes that code vector and produces translations character by character\n",
    "\n",
    "Than it gets fed into a model that follows this simple interface:\n",
    "* __`model.symbolic_translate(inp, **flags) -> out, logp`__ - takes symbolic int32 matrix of hebrew words, produces output tokens sampled from the model and output log-probabilities for all possible tokens at each tick.\n",
    "* __`model.symbolic_score(inp, out, **flags) -> logp`__ - takes symbolic int32 matrices of hebrew words and their english translations. Computes the log-probabilities of all possible english characters given english prefices and hebrew word.\n",
    "* __`model.weights`__ - weights from all model layers [a list of variables]\n",
    "\n",
    "That's all! It's as hard as it gets. With those two methods alone you can implement all kinds of prediction and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "s = tf.InteractiveSession()\n",
    "\n",
    "# ^^^ if you get \"variable *** already exists\": re-run this cell again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from basic_model import BasicTranslationModel\n",
    "model = BasicTranslationModel('model',inp_voc,out_voc,\n",
    "                              emb_size=32, hid_size=64)\n",
    "\n",
    "# PLEASE DON'T CHANGE THESE VALUES: emb_size=32, hid_size=64\n",
    "\n",
    "s.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Symbolic_translate output:\n",
      " Tensor(\"PlaceholderWithDefault_1:0\", shape=(?, ?), dtype=int32) (<tf.Tensor 'transpose_2:0' shape=(?, ?) dtype=int32>, <tf.Tensor 'Reshape_1:0' shape=(?, ?, 283) dtype=float32>)\n",
      "\n",
      "Sample translations:\n",
      " [[6 9 1 6 6]\n",
      " [2 9 5 5 2]\n",
      " [5 7 4 9 1]]\n"
     ]
    }
   ],
   "source": [
    "# Play around with symbolic_translate and symbolic_score\n",
    "inp = tf.placeholder_with_default(np.random.randint(0,10,[3,5],dtype='int32'),[None,None])\n",
    "out = tf.placeholder_with_default(np.random.randint(0,10,[3,5],dtype='int32'),[None,None])\n",
    "\n",
    "# translate inp (with untrained model)\n",
    "sampled_out, logp = out,model.symbolic_translate(inp, greedy=False)\n",
    "print(\"\\nSymbolic_translate output:\\n\",out,logp)\n",
    "print(\"\\nSample translations:\\n\", s.run(sampled_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Symbolic_score output:\n",
      " Tensor(\"Reshape_3:0\", shape=(?, ?, 283), dtype=float32)\n",
      "\n",
      "Log-probabilities (clipped):\n",
      " [[[  0.         -69.0775528  -69.0775528  -69.0775528  -69.0775528 ]\n",
      "  [ -5.67120266  -5.63176012  -5.6199317   -5.62162685  -5.65588379]]\n",
      "\n",
      " [[  0.         -69.0775528  -69.0775528  -69.0775528  -69.0775528 ]\n",
      "  [ -5.63648033  -5.63027096  -5.65016413  -5.64973164  -5.62057209]]\n",
      "\n",
      " [[  0.         -69.0775528  -69.0775528  -69.0775528  -69.0775528 ]\n",
      "  [ -5.66716003  -5.62641335  -5.66799974  -5.62680292  -5.64094496]]]\n"
     ]
    }
   ],
   "source": [
    "# score logp(out | inp) with untrained input\n",
    "logp = model.symbolic_score(inp,out)\n",
    "print(\"\\nSymbolic_score output:\\n\",logp)\n",
    "print(\"\\nLog-probabilities (clipped):\\n\", s.run(logp)[:,:2,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare any operations you want here\n",
    "input_sequence = tf.placeholder('int32', [None,None])\n",
    "greedy_translations, logp = <build symbolic translations with greedy=True>\n",
    "    \n",
    "def translate(lines):\n",
    "    \"\"\"\n",
    "    You are given a list of input lines. \n",
    "    Make your neural network translate them.\n",
    "    :return: a list of output lines\n",
    "    \"\"\"\n",
    "    # Convert lines to a matrix of indices\n",
    "    lines_ix = <YOUR CODE>\n",
    "\n",
    "    # Compute translations in form of indices\n",
    "    trans_ix = s.run(greedy_translations, {<YOUR CODE - feed dict>})\n",
    "\n",
    "    # Convert translations back into strings\n",
    "    return out_voc.to_lines(trans_ix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Sample inputs:\",all_words[:3])\n",
    "print(\"Dummy translations:\",translate(all_words[:3]))\n",
    "\n",
    "assert isinstance(greedy_translations,tf.Tensor) and greedy_translations.dtype.is_integer, \"trans must be a tensor of integers (token ids)\"\n",
    "assert translate(all_words[:3]) == translate(all_words[:3]), \"make sure translation is deterministic (use greedy=True and disable any noise layers)\"\n",
    "assert type(translate(all_words[:3])) is list and (type(translate(all_words[:1])[0]) is str or type(translate(all_words[:1])[0]) is unicode), \"translate(lines) must return a sequence of strings!\"\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring function\n",
    "\n",
    "LogLikelihood is a poor estimator of model performance.\n",
    "* If we predict zero probability once, it shouldn't ruin entire model.\n",
    "* It is enough to learn just one translation if there are several correct ones.\n",
    "* What matters is how many mistakes model's gonna make when it translates!\n",
    "\n",
    "Therefore, we will use minimal Levenshtein distance. It measures how many characters do we need to add/remove/replace from model translation to make it perfect. Alternatively, one could use character-level BLEU/RougeL or other similar metrics.\n",
    "\n",
    "The catch here is that Levenshtein distance is not differentiable: it isn't even continuous. We can't train our neural network to maximize it by gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import editdistance # !pip install editdistance\n",
    "\n",
    "def get_distance(word,trans):\n",
    "    \"\"\"\n",
    "    A function that takes word and predicted translation\n",
    "    and evaluates (Levenshtein's) edit distance to closest correct translation\n",
    "    \"\"\"\n",
    "    references = word_to_translation[word]\n",
    "    assert len(references)!=0,\"wrong/unknown word\"\n",
    "    return min(editdistance.eval(trans,ref) for ref in references)\n",
    "\n",
    "def score(words, bsize=100):\n",
    "    \"\"\"a function that computes levenshtein distance for bsize random samples\"\"\"\n",
    "    assert isinstance(words,np.ndarray)\n",
    "    \n",
    "    batch_words = np.random.choice(words,size=bsize,replace=False)\n",
    "    batch_trans = translate(batch_words)\n",
    "    \n",
    "    distances = list(map(get_distance,batch_words,batch_trans))\n",
    "    \n",
    "    return np.array(distances,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#should be around 5-50 and decrease rapidly after training :)\n",
    "[score(test_words,10).mean() for _ in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training (2 points)\n",
    "\n",
    "Here we define a function that trains our model through maximizing log-likelihood a.k.a. minimizing crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import utility functions\n",
    "from basic_model_tf import initialize_uninitialized, infer_length, infer_mask, select_values_over_last_axis\n",
    "\n",
    "class supervised_training:\n",
    "\n",
    "    # variable for inputs and correct answers\n",
    "    input_sequence = tf.placeholder('int32',[None,None])\n",
    "    reference_answers = tf.placeholder('int32',[None,None])\n",
    "    \n",
    "    # Compute log-probabilities of all possible tokens at each step. Use model interface.\n",
    "    logprobs_seq = <YOUR CODE>\n",
    "    \n",
    "    # compute mean crossentropy\n",
    "    crossentropy = - select_values_over_last_axis(logprobs_seq,reference_answers)\n",
    "    \n",
    "    mask = infer_mask(reference_answers, out_voc.eos_ix)\n",
    "    \n",
    "    loss = tf.reduce_sum(crossentropy * mask)/tf.reduce_sum(mask)\n",
    "    \n",
    "    # Build weights optimizer. Use model.weights to get all trainable params.\n",
    "    train_step = <YOUR CODE>\n",
    "    \n",
    "    \n",
    "# intialize optimizer params while keeping model intact\n",
    "initialize_uninitialized(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually run training on minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def sample_batch(words, word_to_translation, batch_size):\n",
    "    \"\"\"\n",
    "    sample random batch of words and random correct translation for each word\n",
    "    example usage:\n",
    "    batch_x,batch_y = sample_batch(train_words, word_to_translations,10)\n",
    "    \"\"\"\n",
    "    #choose words\n",
    "    batch_words = np.random.choice(words,size=batch_size)\n",
    "    \n",
    "    #choose translations\n",
    "    batch_trans_candidates = list(map(word_to_translation.get,batch_words))\n",
    "    batch_trans = list(map(random.choice,batch_trans_candidates))\n",
    "    \n",
    "    return inp_voc.to_matrix(batch_words), out_voc.to_matrix(batch_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bx,by = sample_batch(train_words, word_to_translation, batch_size=3)\n",
    "print(\"Source:\")\n",
    "print(bx)\n",
    "print(\"Target:\")\n",
    "print(by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm,trange #or use tqdm_notebook,tnrange\n",
    "\n",
    "loss_history=[]\n",
    "editdist_history = []\n",
    "\n",
    "for i in trange(25000):\n",
    "    bx,by = sample_batch(train_words, word_to_translation, 32)\n",
    "    \n",
    "    feed_dict = {\n",
    "        supervised_training.input_sequence:bx,\n",
    "        supervised_training.reference_answers:by\n",
    "    }\n",
    "    \n",
    "    loss,_ = s.run([supervised_training.loss,supervised_training.train_step],feed_dict)\n",
    "    loss_history.append(loss)\n",
    "    \n",
    "    if (i+1)%REPORT_FREQ==0:\n",
    "        clear_output(True)\n",
    "        current_scores = score(test_words)\n",
    "        editdist_history.append(current_scores.mean())\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.subplot(131)\n",
    "        plt.title('train loss / traning time')\n",
    "        plt.plot(loss_history)\n",
    "        plt.grid()\n",
    "        plt.subplot(132)\n",
    "        plt.title('val score distribution')\n",
    "        plt.hist(current_scores, bins = 20)\n",
    "        plt.subplot(133)\n",
    "        plt.title('val score / traning time')\n",
    "        plt.plot(editdist_history)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        print(\"llh=%.3f, mean score=%.3f\"%(np.mean(loss_history[-10:]),np.mean(editdist_history[-10:])))\n",
    "        \n",
    "# Note: it's okay if loss oscillates up and down as long as it gets better on average over long term (e.g. 5k batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in train_words[:10]:\n",
    "    print(\"%s -> %s\"%(word,translate([word])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "for start_i in trange(0,len(test_words),32):\n",
    "    batch_words = test_words[start_i:start_i+32]\n",
    "    batch_trans = translate(batch_words)\n",
    "    distances = list(map(get_distance,batch_words,batch_trans))\n",
    "    test_scores.extend(distances)\n",
    "    \n",
    "print(\"Supervised test score:\", np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Make it actually work (up to 26 points)\n",
    "\n",
    "In this section we want you to experiment to find a good model for the task.\n",
    "\n",
    "**What would be good**:\n",
    "\n",
    "1) try different recurrent units\n",
    "\n",
    "2) implement attention - compulsory!\n",
    "\n",
    "3) try bidirectional rnn/gru/lstm\n",
    "\n",
    "4) try different functions for attention\n",
    "\n",
    "5) any other ideas are welcome!\n",
    "\n",
    "**Requirements**:\n",
    "\n",
    "1) less than 1.2 llh\n",
    "\n",
    "2) less than 6 points test score\n",
    "\n",
    "3) don't change emb_size=32, hid_size=64 (if you're using bidirectional rnn, hid size for each must be 32 to get overall hid_size=64)\n",
    "\n",
    "**What we expect to get**:\n",
    "\n",
    "1) results with models in this notebook (top-n models)\n",
    "\n",
    "2) a brief report describing your experiments and results: what have you tried, why, etc.\n",
    "\n",
    "**What files you need to send**:\n",
    "\n",
    "1) this notebook\n",
    "\n",
    "2) file .py similar to ours basic_model.py with all your models and attentions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the version of attention template: you can use it if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttentionLayer:\n",
    "    def __init__(self, name, enc_size, dec_size, hid_size, activ=tf.tanh):\n",
    "        \"\"\"\n",
    "        A basic layer that computes attention weights and response\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.enc_size = enc_size\n",
    "        self.dec_size = dec_size\n",
    "        self.hid_size = hid_size\n",
    "        self.activ = activ\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            self.dec = tf.get_variable('dec', shape=[dec_size, hid_size])\n",
    "            self.enc = tf.get_variable('enc', shape=[enc_size, hid_size])\n",
    "            self.vec = tf.get_variable('vec', shape=[hid_size, 1])[:, 0]\n",
    "\n",
    "    def __call__(self, enc, dec, inp_mask):\n",
    "        \"\"\"\n",
    "        Computes attention response and weights\n",
    "        Input shapes:\n",
    "        enc: [batch_size, ninp, enc_size]\n",
    "        dec: [batch_size, dec_size]\n",
    "        inp_mask: [batch_size, ninp]\n",
    "        Output shapes:\n",
    "        attn: [batch_size, enc_size]\n",
    "        probs: [batch_size, ninp]\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(self.name):\n",
    "            # Compute hiddens.\n",
    "            # in case of LSTM it is tuple (hid_state, cell_state)\n",
    "            <your code here>\n",
    "\n",
    "            # attention\n",
    "            <your code here>\n",
    "            scores = <your code here> # [batch_size, ninp]\n",
    "\n",
    "            # Compute probabilities\n",
    "            <your code here>\n",
    "            probs = <your code here>\n",
    "\n",
    "            # Compose attention.\n",
    "            <your code here>\n",
    "            attn = <your code here>\n",
    "\n",
    "            return attn, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`[your report/log here or anywhere you please]`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
