{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vowpal Wabbit в NLP\n",
    "Автоматическая обработка текстов - 2017, семинар 4.\n",
    "\n",
    "В этом семинаре мы познакомимся с библиотекой Vowpal Wabbit и решим с его помощью задачу многоклассовой классификации на больших данных. \n",
    "Данные скачайте [здесь](https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow/data) или запустите следующие две ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wget https://www.dropbox.com/s/r0q0p0uprhcp8bb/train-sample.zip\n",
    "#! unzip train-sample.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wget https://www.dropbox.com/s/50vw2gsglc91f6o/train.zip\n",
    "#! unzip train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы на семинаре не тратить время на обработку и обучение моделей на всех данных, предлагается использовать только небольшую подвыборку (`train-sample.csv`). Но сдавать ноутбук все равно необходимо с результатами на **всех** данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BodyMarkdown': \"I'm new to C#, and I want to use a trackbar for the forms opacity\\nThis is my code\\n\\n    decimal trans = trackBar1.Value / 5000\\n    this.Opacity = trans\\n\\nWhen I try to build it, I get this error\\n\\n**Cannot implicitly convert type 'decimal' to 'double**\\n\\nI tried making trans a double, but then the control doesn't work. This code worked fine for me in VB.NET. Any suggestions?\",\n",
       " 'OpenStatus': 'open',\n",
       " 'OwnerCreationDate': '07/31/2008 21:33:24',\n",
       " 'OwnerUndeletedAnswerCountAtPostTime': '0',\n",
       " 'OwnerUserId': '8',\n",
       " 'PostClosedDate': '',\n",
       " 'PostCreationDate': '07/31/2008 21:42:52',\n",
       " 'PostId': '4',\n",
       " 'ReputationAtPostCreation': '1',\n",
       " 'Tag1': 'c#',\n",
       " 'Tag2': '',\n",
       " 'Tag3': '',\n",
       " 'Tag4': '',\n",
       " 'Tag5': '',\n",
       " 'Title': 'Decimal vs Double?'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "INPUT_DATA = 'train.csv'\n",
    "#INPUT_DATA = 'train-sample.csv'\n",
    "\n",
    "reader = csv.DictReader(open(INPUT_DATA))\n",
    "dict(next(reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый объект выборки соответствует некоторому посту на Stack Overflow. Требуется построить модель, определяющую статус поста. Подробнее про задачу и формат данных можно прочитать на [странице соревнования](https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow).\n",
    "\n",
    "Перед обучением модели из Vowpal Wabbit данные следует сохранить в специальный формат: <br>\n",
    "`label |namespace1 feature1:value1 feature2 feature3:value3 |namespace2 ...` <br>\n",
    "Записи `feature` и `feature:1.0` эквивалентны. Выделение признаков в смысловые подгруппы (namespaces) позволяет создавать взаимодействия между ними. Подробнее про формат входных данных можно прочитать [здесь](https://github.com/JohnLangford/vowpal_wabbit/wiki/Input-format).\n",
    "\n",
    "Ниже реализована функция, которая извлекает признаки с помощью подаваемого на вход экстрактора, разбивает данные на трейн и тест и записывает их на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "STATUSES = ['not a real question', 'not constructive', 'off topic', 'open', 'too localized']\n",
    "STATUS_DICT = {status: i+1 for i, status in enumerate(STATUSES)}\n",
    "\n",
    "def data2vw(features_extractor, train_output='train', test_output='test', ytest_output='ytest'):\n",
    "    reader = csv.DictReader(open(INPUT_DATA, encoding='utf-8'))\n",
    "    writer_train = open(train_output, 'w')\n",
    "    writer_test = open(test_output, 'w')\n",
    "    writer_ytest = open(ytest_output, 'w')\n",
    "    \n",
    "    for row in tqdm_notebook(reader):\n",
    "        label = STATUS_DICT[row['OpenStatus']]\n",
    "        features = features_extractor(row)\n",
    "        output_line = '%s %s\\n' % (label, features)\n",
    "        if int(row['PostId']) % 2 == 0:\n",
    "            writer_train.write(output_line)\n",
    "        else:\n",
    "            writer_test.write(output_line)\n",
    "            writer_ytest.write('%s\\n' % label)\n",
    "            \n",
    "    writer_train.close()\n",
    "    writer_test.close()\n",
    "    writer_ytest.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с простейшей модели. В качестве признаков возьмите заголовки и очистите их: приведите символы к нижнему регистру, удалите пунктуацию. Также приветствуется использование стеммеров/лемматизаторов, однако учтите, что они могут сильно замедлить скорость обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698a4a8d005a4875a8f711bac1251dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4 | decimal vs double\n",
      "4 | percentage width child in absolutely positioned parent doesn't work in ie\n",
      "4 | tools for porting j code to c\n",
      "4 | throw error in mysql trigger\n",
      "4 | what's the difference between math floor and math truncate\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_title(row):\n",
    "    title = row['Title']\n",
    "    words = re.findall('[A-Za-z\\']+', title)\n",
    "    for i in range(len(words)):\n",
    "        words[i] = words[i].lower()\n",
    "    return ' '.join(words)\n",
    "\n",
    "data2vw(lambda row: '| %s' % extract_title(row))\n",
    "! head -n 5 train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим `vw` модель. Параметр `-d` отвечает за путь к обучающей выборке, `-f` – за путь к модели, `--oaa` – за режим мультиклассовой классификации `one-against-all`. Подробное описание всех параметров можно найти [здесь](https://github.com/JohnLangford/vowpal_wabbit/wiki/Command-line-arguments) или вызвать `vw --help`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = train\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        4        1        4\n",
      "0.500000 0.000000            2            2.0        4        4       12\n",
      "0.250000 0.000000            4            4.0        4        4        6\n",
      "0.125000 0.000000            8            8.0        4        4        7\n",
      "0.062500 0.000000           16           16.0        4        4        5\n",
      "0.062500 0.062500           32           32.0        4        4        9\n",
      "0.046875 0.031250           64           64.0        4        4        5\n",
      "0.062500 0.078125          128          128.0        4        4       11\n",
      "0.089844 0.117188          256          256.0        4        4        8\n",
      "0.070312 0.050781          512          512.0        4        4        5\n",
      "0.066406 0.062500         1024         1024.0        4        4        8\n",
      "0.063965 0.061523         2048         2048.0        4        4        6\n",
      "0.056641 0.049316         4096         4096.0        4        4       11\n",
      "0.053345 0.050049         8192         8192.0        4        4        6\n",
      "0.043762 0.034180        16384        16384.0        4        4       14\n",
      "0.033722 0.023682        32768        32768.0        4        4       15\n",
      "0.023727 0.013733        65536        65536.0        4        4        7\n",
      "0.016624 0.009521       131072       131072.0        4        4       12\n",
      "0.011856 0.007088       262144       262144.0        4        4       16\n",
      "0.011803 0.011749       524288       524288.0        4        4       11\n",
      "0.016267 0.020731      1048576      1048576.0        4        4       11\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1685253\n",
      "passes used = 1\n",
      "weighted example sum = 1685253.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.020997\n",
      "total feature number = 15699619\n"
     ]
    }
   ],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим модель к тестовой выборке и сохраним предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "raw predictions = pred\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        4        4        9\n",
      "0.000000 0.000000            2            2.0        4        4        7\n",
      "0.000000 0.000000            4            4.0        4        4        8\n",
      "0.125000 0.250000            8            8.0        4        4        6\n",
      "0.125000 0.125000           16           16.0        4        4        7\n",
      "0.156250 0.187500           32           32.0        4        4       10\n",
      "0.093750 0.031250           64           64.0        4        4        8\n",
      "0.117188 0.140625          128          128.0        4        4        8\n",
      "0.121094 0.125000          256          256.0        4        4       15\n",
      "0.103516 0.085938          512          512.0        4        4       12\n",
      "0.092773 0.082031         1024         1024.0        4        4       12\n",
      "0.083984 0.075195         2048         2048.0        4        4       15\n",
      "0.065918 0.047852         4096         4096.0        4        4        7\n",
      "0.061646 0.057373         8192         8192.0        4        4        5\n",
      "0.050598 0.039551        16384        16384.0        4        4        6\n",
      "0.040283 0.029968        32768        32768.0        4        4       14\n",
      "0.029663 0.019043        65536        65536.0        4        4        9\n",
      "0.021233 0.012802       131072       131072.0        4        4       10\n",
      "0.015789 0.010345       262144       262144.0        4        4        7\n",
      "0.014864 0.013939       524288       524288.0        4        4        5\n",
      "0.018159 0.021454      1048576      1048576.0        4        4       12\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1685275\n",
      "passes used = 1\n",
      "weighted example sum = 1685275.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.022093\n",
      "total feature number = 15704957\n"
     ]
    }
   ],
   "source": [
    "! vw -i model -t test -r pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:-3.96212 2:-5.91553 3:-4.17684 4:2.434 5:-6.30902\r\n",
      "1:-7.23647 2:-7.77868 3:-6.88226 4:4.5498 5:-6.60568\r\n",
      "1:-3.83466 2:-5.41 3:-5.04316 4:2.91026 5:-6.61622\r\n",
      "1:-3.88813 2:-6.19204 3:-6.32849 4:2.96315 5:-6.38496\r\n",
      "1:-5.65263 2:-3.88128 3:-3.87864 4:2.01935 5:-6.2923\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 5 pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию, которая вычисляет `logloss` и `accuracy`, не загружая вектора в память. Используйте `softmax`, чтобы получить вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def count_probas(pred_values):\n",
    "    exps = np.exp(pred_values)\n",
    "    exp_sum = np.sum(exps)\n",
    "    return exps / exp_sum\n",
    "\n",
    "def get_scores(ytest_input='ytest', pred_input='pred'):\n",
    "    n, error, loss = 0, 0, 0\n",
    "    reader_ytest = open(ytest_input, 'r')\n",
    "    reader_pred = open(pred_input, 'r')\n",
    "    \n",
    "    for label, pred in zip(reader_ytest, reader_pred):\n",
    "        temp = pred.split(' ')\n",
    "        pred_values = np.array([float(item.split(':')[1]) for item in temp])\n",
    "        n += 1\n",
    "        if int(label) - 1 != np.argmax(pred_values):\n",
    "            error += 1\n",
    "        probas = count_probas(pred_values)\n",
    "        loss += np.log(probas[int(label) - 1])\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "    reader_ytest.close()\n",
    "    reader_pred.close()\n",
    "    return - loss / n, 1 - float(error) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.14658\n",
      "accuracy = 0.97791\n"
     ]
    }
   ],
   "source": [
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На оригинальных данных `logloss` должен быть меньше `0.20`, `accuracy` больше `0.95`. Если это не так, то скорее всего у вас ошибка.\n",
    "\n",
    "Теперь попробуем улучшить модель, добавив новые признаки, порождаемые словами. В `vowpal wabbit` есть возможность делать это прямо на лету. Воспользуйтесь параметрами `affix`, `ngram`, `skips`.\n",
    "\n",
    "Далее везде при подборе параметров ориентируйтесь на улучшение `logloss`. Используйте `--quiet` или `-P`, чтобы избавиться от длинных выводов при обучении и применении моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vw (parse_args.cc:250): malformed affix argument (length must be 1..7): aff\n",
      "vw (parse_args.cc:250): malformed affix argument (length must be 1..7): aff\n",
      "vw (parse_args.cc:250): malformed affix argument (length must be 1..7): aff\n",
      "vw (parse_args.cc:250): malformed affix argument (length must be 1..7): aff\n",
      "vw (parse_args.cc:250): malformed affix argument (length must be 1..7): aff\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "best_loss, accur = get_scores()\n",
    "best = (0, 0, 0)\n",
    "ngram_param = [0, 1, 2, 3, 4]\n",
    "skips_param = [0, 1, 2, 3, 4]\n",
    "affix_param = [-1, +1, 0, -2, +2]\n",
    "for i in range(5):\n",
    "    ngr = random.choice(ngram_param)\n",
    "    skp = random.choice(skips_param)\n",
    "    aff = random.choice(affix_param)\n",
    "    ! vw -d train --loss_function logistic --oaa 5 --ngram ngr --skips skp --affix aff -f model --quiet\n",
    "    ! vw -i model -t test -r pred --quiet\n",
    "    loss, accur = get_scores()\n",
    "    if best_loss > loss:\n",
    "        best = (ngr, skp, aff)\n",
    "        best_loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss:\n",
      "0.146578691026\n",
      "Best parameters:\n",
      "(0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "print('Best loss:')\n",
    "print(best_loss)\n",
    "print('Best parameters:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто качество `vw` модели получается учушить увеличением числа проходов по обучающей выборке (параметр `--passes`) и увеличением числа бит хэш-функции для уменьшения числа коллизий признаков (параметр `-b`). Подробнее про то, где в `vowpal wabbit` используется хэш-функция, можно прочитать [здесь](https://github.com/JohnLangford/vowpal_wabbit/wiki/Feature-Hashing-and-Extraction). Как меняется качество при изменении этих параметров? Верно ли, что при увеличении значений параметров `--passes` и `-b` качество всегда не убывает и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь интерес представляет то, какие признаки оказались наиболее важными для модели. Для этого сначала переведем модель в читаемый формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 8.1.1\r\n",
      "Min label:-50.000000\r\n",
      "Max label:50.000000\r\n",
      "bits:18\r\n",
      "lda:0\r\n",
      "0 ngram: \r\n",
      "0 skip: \r\n",
      "options: --oaa 5\r\n",
      "Checksum: -830150891\r\n",
      ":0\r\n",
      "':82960:-1.101947\r\n",
      "'':145776:-1.849990\r\n",
      "''':183184:-0.954318\r\n",
      "'''':221848:-0.855841\r\n",
      "''''[1]:221849:-0.787449\r\n",
      "''''[2]:221850:-0.899348\r\n",
      "''''[3]:221851:0.162724\r\n",
      "''''[4]:221852:-0.190776\r\n",
      "'''[1]:183185:-0.814208\r\n",
      "'''[2]:183186:-1.086044\r\n",
      "'''[3]:183187:1.082939\r\n",
      "'''[4]:183188:-0.939128\r\n",
      "''[1]:145777:-1.254720\r\n",
      "''[2]:145778:-1.245932\r\n",
      "''[3]:145779:1.351760\r\n",
      "''[4]:145780:-1.752311\r\n",
      "''assembler'':183600:-0.296368\r\n",
      "''assembler''[1]:183601:-0.374649\r\n",
      "''assembler''[2]:183602:-0.444131\r\n",
      "''assembler''[3]:183603:0.483609\r\n"
     ]
    }
   ],
   "source": [
    "! vw -i model -t --invert_hash model.readable train --quiet\n",
    "! head -n 30 model.readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первые несколько строк соответствуют информации о модели. Далее следуют строчки вида `feature[label]:hash:weight`. Выделите для каждого класса 10 признаков с наибольшими по модулю весами. Постарайтесь сделать ваш алгоритм прохода по файлу константным по памяти. Например, можно воспользоваться [кучей](https://docs.python.org/2/library/heapq.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_weight_features(n_features, class_num, model_input = 'model.readable'):\n",
    "    h = []\n",
    "    line_count = 0\n",
    "    model = open(model_input, 'r')\n",
    "    for feature in model:\n",
    "        if line_count > 9:\n",
    "            params = feature.strip().split(':')\n",
    "            if class_num != 0:\n",
    "                if len(params[0]) > 1 and params[0][-2] == str(class_num):\n",
    "                    heapq.heappush(h, (abs(float(params[2])), float(params[2]), \n",
    "                                       params[0], int(params[1])))\n",
    "                    if len(h) > n_features:\n",
    "                        heapq.heappop(h)\n",
    "            else:\n",
    "                if params[0][-1] != ']':\n",
    "                    heapq.heappush(h, (abs(float(params[2])), float(params[2]), \n",
    "                                       params[0], int(params[1])))\n",
    "                    if len(h) > n_features:\n",
    "                        heapq.heappop(h)\n",
    "        else:\n",
    "            line_count += 1\n",
    "    return list(reversed(sorted(h)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max weighted features for 0-th class:\n",
      "(4.665564, -4.665564, 'uitableviewcell', 261952)\n",
      "(4.665564, -4.665564, 'templatingengine', 261952)\n",
      "(4.665564, -4.665564, 'simplink', 261952)\n",
      "(4.665564, -4.665564, 'runtimeinvisibleparameterannotations', 261952)\n",
      "(4.665564, -4.665564, 'gtkviewtree', 261952)\n",
      "(4.665564, -4.665564, 'businessconnectornet', 261952)\n",
      "(4.574079, -4.574079, 'robotlegs', 15552)\n",
      "(4.574079, -4.574079, \"eq'\", 15552)\n",
      "(4.574079, -4.574079, 'coregrahpics', 15552)\n",
      "(4.574079, -4.574079, 'compund', 15552)\n",
      "Max weighted features for 1-th class:\n",
      "(3.047302, -3.047302, 'uploading[1]', 72969)\n",
      "(3.047302, -3.047302, 'namelength[1]', 72969)\n",
      "(3.047302, -3.047302, 'mysqldb[1]', 72969)\n",
      "(3.047302, -3.047302, 'getpropertyaction[1]', 72969)\n",
      "(3.047302, -3.047302, 'eacel[1]', 72969)\n",
      "(3.047302, -3.047302, 'clearcacheinterceptor[1]', 72969)\n",
      "(3.006469, -3.006469, 'overlay[1]', 67377)\n",
      "(2.968956, -2.968956, 'strange[1]', 260657)\n",
      "(2.968956, -2.968956, 'reorganization[1]', 260657)\n",
      "(2.968956, -2.968956, 'pth[1]', 260657)\n",
      "Max weighted features for 2-th class:\n",
      "(4.574401, -4.574401, 'topath[2]', 208218)\n",
      "(4.574401, -4.574401, 'replacint[2]', 208218)\n",
      "(4.574401, -4.574401, 'questioon[2]', 208218)\n",
      "(4.574401, -4.574401, \"pasword'[2]\", 208218)\n",
      "(4.574401, -4.574401, 'listview[2]', 208218)\n",
      "(4.199947, -4.199947, 'whittle[2]', 27370)\n",
      "(4.199947, -4.199947, 'tservice[2]', 27370)\n",
      "(4.199947, -4.199947, 'sharedworkers[2]', 27370)\n",
      "(4.199947, -4.199947, 'selectgroupbyinto[2]', 27370)\n",
      "(4.199947, -4.199947, 'pass[2]', 27370)\n",
      "Max weighted features for 3-th class:\n",
      "(3.129584, 3.129584, 'uiwebview[3]', 65611)\n",
      "(3.129584, 3.129584, 'mulitithreading[3]', 65611)\n",
      "(3.129584, 3.129584, \"mo'[3]\", 65611)\n",
      "(3.129584, 3.129584, 'exepct[3]', 65611)\n",
      "(3.129584, 3.129584, 'devicedefault[3]', 65611)\n",
      "(3.129584, 3.129584, 'cssclasses[3]', 65611)\n",
      "(3.020383, 3.020383, 'tinybit[3]', 103203)\n",
      "(3.020383, 3.020383, 'nswindowflipper[3]', 103203)\n",
      "(3.020383, 3.020383, 'logoutrequest[3]', 103203)\n",
      "(3.020383, 3.020383, 'hql[3]', 103203)\n",
      "Max weighted features for 4-th class:\n",
      "(4.55772, -4.55772, 'virtualmin[4]', 77612)\n",
      "(4.55772, -4.55772, 'primitivevalueforkey[4]', 77612)\n",
      "(4.55772, -4.55772, 'connecting[4]', 77612)\n",
      "(4.5149, -4.5149, 'uiwebview[4]', 65612)\n",
      "(4.5149, -4.5149, 'mulitithreading[4]', 65612)\n",
      "(4.5149, -4.5149, \"mo'[4]\", 65612)\n",
      "(4.5149, -4.5149, 'exepct[4]', 65612)\n",
      "(4.5149, -4.5149, 'devicedefault[4]', 65612)\n",
      "(4.5149, -4.5149, 'cssclasses[4]', 65612)\n",
      "(4.467386, -4.467386, 'payflowpro[4]', 89076)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    maxw_features = max_weight_features(10, i)\n",
    "    print('Max weighted features for {}-th class:'.format(i))\n",
    "    for feature in maxw_features:\n",
    "        print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Добавим признаки, извлеченные из текста поста (поле `BodyMarkdown`). В этом поле находится более подробная информация о вопросе, и часто туда помещают код, формулы и т.д. При удалении пунктуации мы потеряем много полезной информации, однако модель \"мешка слов\" на сырых данных может сильно раздуть признаковое пространство. В таких случаях работают с n-граммами на символах. <br>\n",
    "Будьте осторожны: символы \"`:`\" и \"`|`\" нельзя использовать в названиях признаков, поскольку они являются служебными для `vw`-формата. Замените эти символы на два других редко встречающихся в выборке (или вообще не встречающихся). Также не забудьте про \"`\\n`\". <br>\n",
    "Поскольку для каждого документа одна n-грамма может встретиться далеко не один раз, то будет экономнее записывать признаки в формате `[n-грамма]:[число вхождений]`.\n",
    "\n",
    "Также добавьте тэги (поля вид `TagN`). Придумайте и извлеките признаки из других полей. Только не используйте `PostClosedDate` – в нем содержится информация о таргете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "def extract_ngram_body(row, ngram=3):\n",
    "    mark_down = row['BodyMarkdown']\n",
    "    words = re.findall('[A-Za-z\\']+', title)\n",
    "    for i in range(len(words)):\n",
    "        words[i] = words[i].lower()\n",
    "    ngrams = Counter()\n",
    "    for word in words:\n",
    "        for i in range(len(word) - ngram + 1):\n",
    "            ngrams[word[i:i+ngram]] += 1\n",
    "    return ngrams\n",
    "\n",
    "def extract_tags(row):\n",
    "    tags = defaultdict(str)\n",
    "    for i in range(1, 6):\n",
    "        tags['Tag' + str(i)] = row['Tag' + str(i)]\n",
    "    return tags\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим все вместе. Реализуйте экстрактор признаков, который выделяет каждую подгруппу в отдельный namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extractors_list = [\n",
    "    ('t', extract_title), \n",
    "    ('b', extract_ngram_body), \n",
    "    ('a', extract_tags)\n",
    "] # (namespace, extractor)\n",
    "\n",
    "\n",
    "def make_feature_extractor(extractors_list):\n",
    "    def feature_extractor(row):\n",
    "    return feature_extractor\n",
    "    \n",
    "    \n",
    "data2vw(make_feature_extractor(extractors_list))\n",
    "\n",
    "! head -n 1 train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэкспериментируйте с другими параметрами модели. Добавьте квадратичные взаимодействия между различными блоками признаков, измените параметры оптимизатора, добавьте регуляризацию и т.д. <br>\n",
    "Выберите не менее трех параметров (и дискретные, и непрерывные). Для каждого из них объясните, почему по вашему мнению его изменение может улучшить качество модели, подберите оптимальное значение. Можете перебрать несколько значений в цикле, но лучше воспользоваться [vw-hypersearch](https://github.com/JohnLangford/vowpal_wabbit/wiki/Using-vw-hypersearch) или [vw-hyperopt](https://github.com/JohnLangford/vowpal_wabbit/blob/master/utl/vw-hyperopt.py) ([статья на хабре](https://habrahabr.ru/company/dca/blog/272697/)). Удобночитаемый вывод и/или графики для разных значений параметров обязательны.\n",
    "\n",
    "Совсем необязательно добиваться наилучшего качества. Для нас важнее то, насколько хорошо вы разобрались с возможностями библиотеки и продемонстрировали это.\n",
    "\n",
    "\n",
    "Помогло ли добавление квадратичных взаимодействий? Каких групп признаков? Какие параметры повлияли на улучшение качества сильнее всего?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Приблизительная разбалловка:\n",
    "* 3 балла в верно реализованные функции\n",
    "* 1 балл за ответ на вопрос про параметры `--passes` и `-b` (с графиком/выводом)\n",
    "* 2 балла за эффективное нахождение наиболее значимых признаков\n",
    "* 1 балл за добавление своих признаков\n",
    "* 3 балла за финальную часть (квадратичные взаимодействия, подбор параметров, графики/вывод и комментарии)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
