{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#                                                                             #\n",
    "#                                INPUT DATA                                   #\n",
    "#                                                                             #\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def read_tags(path):\n",
    "    file = open(path, 'r')\n",
    "    return [line.strip() for line in file]\n",
    "    \"\"\"\n",
    "    Read a list of possible tags from file and return the list.\n",
    "    \"\"\"\n",
    "\n",
    "# Word: str\n",
    "# Sentence: list of str\n",
    "# TaggedSentence: list of TaggedWord\n",
    "# Tags: list of TaggedWord\n",
    "# TagLattice: list of Tags\n",
    "\n",
    "\n",
    "def read_tagged_sentences(path):\n",
    "    TaggedWord = collections.namedtuple('TaggedWord', ['text', 'tag'])\n",
    "    file = open(path, 'r')\n",
    "    lines = [line for line in file]\n",
    "    \n",
    "    \"\"\"\n",
    "    Read tagged sentences from file and return array of TaggedSentence.\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "def write_tagged_sentence(tagged_sentence, f):\n",
    "    \"\"\"\n",
    "    Write tagged sentence to file-like object f.\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "\n",
    "TaggingQuality = collections.namedtuple('TaggingQuality', ['acc'])\n",
    "\n",
    "\n",
    "def tagging_quality(ref, out):\n",
    "    \"\"\"\n",
    "    Compute tagging quality and reutrn TaggingQuality object.\n",
    "    \"\"\"\n",
    "    nwords = 0\n",
    "    ncorrect = 0\n",
    "    import itertools\n",
    "    for ref_sentence, out_sentence in itertools.zip_longest(ref, out):\n",
    "        for ref_word, out_word in itertools.zip_longest():\n",
    "            ...\n",
    "    return ncorrect / nwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# newdoc id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713\n",
      "\n",
      "# sent_id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0001\n",
      "\n",
      "# text = From the AP comes this story :\n",
      "\n",
      "1\tFrom\tfrom\tADP\tIN\t_\t3\tcase\t_\t_\n",
      "\n",
      "2\tthe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t3\tdet\t_\t_\n",
      "\n",
      "3\tAP\tAP\tPROPN\tNNP\tNumber=Sing\t4\tobl\t_\t_\n",
      "\n",
      "4\tcomes\tcome\tVERB\tVBZ\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t0\troot\t_\t_\n",
      "\n",
      "5\tthis\tthis\tDET\tDT\tNumber=Sing|PronType=Dem\t6\tdet\t_\t_\n",
      "\n",
      "6\tstory\tstory\tNOUN\tNN\tNumber=Sing\t4\tnsubj\t_\t_\n",
      "\n",
      "7\t:\t:\tPUNCT\t:\t_\t4\tpunct\t_\t_\n",
      "\n",
      "\n",
      "\n",
      "# sent_id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0002\n",
      "\n",
      "# text = President Bush on Tuesday nominated two individuals to replace retiring jurists on federal courts in the Washington area.\n",
      "\n",
      "1\tPresident\tPresident\tPROPN\tNNP\tNumber=Sing\t5\tnsubj\t_\t_\n",
      "\n",
      "2\tBush\tBush\tPROPN\tNNP\tNumber=Sing\t1\tflat\t_\t_\n",
      "\n",
      "3\ton\ton\tADP\tIN\t_\t4\tcase\t_\t_\n",
      "\n",
      "4\tTuesday\tTuesday\tPROPN\tNNP\tNumber=Sing\t5\tobl\t_\t_\n",
      "\n",
      "5\tnominated\tnominate\tVERB\tVBD\tMood=Ind|Tense=Past|VerbForm=Fin\t0\troot\t_\t_\n",
      "\n",
      "6\ttwo\ttwo\tNUM\tCD\tNumType=Card\t7\tnummod\t_\t_\n",
      "\n",
      "7\tindividuals\tindividual\tNOUN\tNNS\tNumber=Plur\t5\tobj\t_\t_\n",
      "\n",
      "8\tto\tto\tPART\tTO\t_\t9\tmark\t_\t_\n",
      "\n",
      "9\treplace\treplace\tVERB\tVB\tVerbForm=Inf\t5\tadvcl\t_\t_\n",
      "\n",
      "10\tretiring\tretire\tVERB\tVBG\tVerbForm=Ger\t11\tamod\t_\t_\n",
      "\n",
      "11\tjurists\tjurist\tNOUN\tNNS\tNumber=Plur\t9\tobj\t_\t_\n",
      "\n",
      "12\ton\ton\tADP\tIN\t_\t14\tcase\t_\t_\n",
      "\n",
      "13\tfederal\tfederal\tADJ\tJJ\tDegree=Pos\t14\tamod\t_\t_\n",
      "\n",
      "14\tcourts\tcourt\tNOUN\tNNS\tNumber=Plur\t11\tnmod\t_\t_\n",
      "\n",
      "15\tin\tin\tADP\tIN\t_\t18\tcase\t_\t_\n",
      "\n",
      "16\tthe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t18\tdet\t_\t_\n",
      "\n",
      "17\tWashington\tWashington\tPROPN\tNNP\tNumber=Sing\t18\tcompound\t_\t_\n",
      "\n",
      "18\tarea\tarea\tNOUN\tNN\tNumber=Sing\t14\tnmod\t_\tSpaceAfter=No\n",
      "\n",
      "19\t.\t.\tPUNCT\t.\t_\t5\tpunct\t_\t_\n",
      "\n",
      "\n",
      "\n",
      "# sent_id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0003\n",
      "\n",
      "# text = Bush nominated Jennifer M. Anderson for a 15-year term as associate judge of the Superior Court of the District of Columbia, replacing Steffen W. Graae.\n",
      "\n",
      "1\tBush\tBush\tPROPN\tNNP\tNumber=Sing\t2\tnsubj\t_\t_\n",
      "\n",
      "2\tnominated\tnominate\tVERB\tVBD\tMood=Ind|Tense=Past|VerbForm=Fin\t0\troot\t_\t_\n",
      "\n",
      "3\tJennifer\tJennifer\tPROPN\tNNP\tNumber=Sing\t2\tobj\t_\t_\n",
      "\n",
      "4\tM.\tM.\tPROPN\tNNP\tNumber=Sing\t3\tflat\t_\t_\n",
      "\n",
      "5\tAnderson\tAnderson\tPROPN\tNNP\tNumber=Sing\t3\tflat\t_\t_\n",
      "\n",
      "6\tfor\tfor\tADP\tIN\t_\t11\tcase\t_\t_\n",
      "\n",
      "7\ta\ta\tDET\tDT\tDefinite=Ind|PronType=Art\t11\tdet\t_\t_\n",
      "\n",
      "8\t15\t15\tNUM\tCD\tNumType=Card\t10\tnummod\t_\tSpaceAfter=No\n",
      "\n",
      "9\t-\t-\tPUNCT\tHYPH\t_\t10\tpunct\t_\tSpaceAfter=No\n",
      "\n",
      "10\tyear\tyear\tNOUN\tNN\tNumber=Sing\t11\tcompound\t_\t_\n",
      "\n",
      "11\tterm\tterm\tNOUN\tNN\tNumber=Sing\t2\tobl\t_\t_\n",
      "\n",
      "12\tas\tas\tADP\tIN\t_\t14\tcase\t_\t_\n",
      "\n",
      "13\tassociate\tassociate\tADJ\tJJ\tDegree=Pos\t14\tamod\t_\t_\n",
      "\n",
      "14\tjudge\tjudge\tNOUN\tNN\tNumber=Sing\t11\tnmod\t_\t_\n",
      "\n",
      "15\tof\tof\tADP\tIN\t_\t18\tcase\t_\t_\n",
      "\n",
      "16\tthe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t18\tdet\t_\t_\n",
      "\n",
      "17\tSuperior\tSuperior\tPROPN\tNNP\tNumber=Sing\t18\tcompound\t_\t_\n",
      "\n",
      "18\tCourt\tCourt\tPROPN\tNNP\tNumber=Sing\t14\tnmod\t_\t_\n",
      "\n",
      "19\tof\tof\tADP\tIN\t_\t21\tcase\t_\t_\n",
      "\n",
      "20\tthe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t21\tdet\t_\t_\n",
      "\n",
      "21\tDistrict\tDistrict\tPROPN\tNNP\tNumber=Sing\t18\tnmod\t_\t_\n",
      "\n",
      "22\tof\tof\tADP\tIN\t_\t23\tcase\t_\t_\n",
      "\n",
      "23\tColumbia\tColumbia\tPROPN\tNNP\tNumber=Sing\t21\tnmod\t_\tSpaceAfter=No\n",
      "\n",
      "24\t,\t,\tPUNCT\t,\t_\t2\tpunct\t_\t_\n",
      "\n",
      "25\treplacing\treplace\tVERB\tVBG\tVerbForm=Ger\t2\tadvcl\t_\t_\n",
      "\n",
      "26\tSteffen\tSteffen\tPROPN\tNNP\tNumber=Sing\t25\tobj\t_\t_\n",
      "\n",
      "27\tW.\tW.\tPROPN\tNNP\tNumber=Sing\t26\tflat\t_\t_\n",
      "\n",
      "28\tGraae\tGraae\tPROPN\tNNP\tNumber=Sing\t26\tflat\t_\tSpaceAfter=No\n",
      "\n",
      "29\t.\t.\tPUNCT\t.\t_\t2\tpunct\t_\t_\n",
      "\n",
      "\n",
      "\n",
      "# sent_id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0004\n",
      "\n",
      "# text = ***\n",
      "\n",
      "1\t***\t***\tPUNCT\tNFP\t_\t0\troot\t_\t_\n",
      "\n",
      "\n",
      "\n",
      "# sent_id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0005\n",
      "\n",
      "# text = Bush also nominated A. Noel Anketell Kramer for a 15-year term as associate judge of the District of Columbia Court of Appeals, replacing John Montague Steadman.\n",
      "\n",
      "1\tBush\tBush\tPROPN\tNNP\tNumber=Sing\t3\tnsubj\t_\t_\n",
      "\n",
      "2\talso\talso\tADV\tRB\t_\t3\tadvmod\t_\t_\n",
      "\n",
      "3\tnominated\tnominate\tVERB\tVBD\tMood=Ind|Tense=Past|VerbForm=Fin\t0\troot\t_\t_\n",
      "\n",
      "4\tA.\tA.\tPROPN\tNNP\tNumber=Sing\t3\tobj\t_\t_\n",
      "\n",
      "5\tNoel\tNoel\tPROPN\tNNP\tNumber=Sing\t4\tflat\t_\t_\n",
      "\n",
      "6\tAnketell\tAnketell\tPROPN\tNNP\tNumber=Sing\t4\tflat\t_\t_\n",
      "\n",
      "7\tKramer\tKramer\tPROPN\tNNP\tNumber=Sing\t4\tflat\t_\t_\n",
      "\n",
      "8\tfor\tfor\tADP\tIN\t_\t13\tcase\t_\t_\n",
      "\n",
      "9\ta\ta\tDET\tDT\tDefinite=Ind|PronType=Art\t13\tdet\t_\t_\n",
      "\n",
      "10\t15\t15\tNUM\tCD\tNumType=Card\t12\tnummod\t_\tSpaceAfter=No\n",
      "\n",
      "11\t-\t-\tPUNCT\tHYPH\t_\t12\tpunct\t_\tSpaceAfter=No\n",
      "\n",
      "12\tyear\tyear\tNOUN\tNN\tNumber=Sing\t13\tcompound\t_\t_\n",
      "\n",
      "13\tterm\tterm\tNOUN\tNN\tNumber=Sing\t3\tobl\t_\t_\n",
      "\n",
      "14\tas\tas\tADP\tIN\t_\t16\tcase\t_\t_\n",
      "\n",
      "15\tassociate\tassociate\tADJ\tJJ\tDegree=Pos\t16\tamod\t_\t_\n",
      "\n",
      "16\tjudge\tjudge\tNOUN\tNN\tNumber=Sing\t13\tnmod\t_\t_\n",
      "\n",
      "17\tof\tof\tADP\tIN\t_\t19\tcase\t_\t_\n",
      "\n",
      "18\tthe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t19\tdet\t_\t_\n",
      "\n",
      "19\tDistrict\tDistrict\tPROPN\tNNP\tNumber=Sing\t16\tnmod\t_\t_\n",
      "\n",
      "20\tof\tof\tADP\tIN\t_\t22\tcase\t_\t_\n",
      "\n",
      "21\tColumbia\tColumbia\tPROPN\tNNP\tNumber=Sing\t22\tcompound\t_\t_\n",
      "\n",
      "22\tCourt\tCourt\tPROPN\tNNP\tNumber=Sing\t19\tnmod\t_\t_\n",
      "\n",
      "23\tof\tof\tADP\tIN\t_\t24\tcase\t_\t_\n",
      "\n",
      "24\tAppeals\tAppeals\tPROPN\tNNPS\tNumber=Plur\t22\tnmod\t_\tSpaceAfter=No\n",
      "\n",
      "25\t,\t,\tPUNCT\t,\t_\t3\tpunct\t_\t_\n",
      "\n",
      "26\treplacing\treplace\tVERB\tVBG\tVerbForm=Ger\t3\tadvcl\t_\t_\n",
      "\n",
      "27\tJohn\tJohn\tPROPN\tNNP\tNumber=Sing\t26\tobj\t_\t_\n",
      "\n",
      "28\tMontague\tMontague\tPROPN\tNNP\tNumber=Sing\t27\tflat\t_\t_\n",
      "\n",
      "29\tSteadman\tSteadman\tPROPN\tNNP\tNumber=Sing\t27\tflat\t_\tSpaceAfter=No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kek = open('data/en-ud-debug.conllu', 'r')\n",
    "i = 0\n",
    "lines = [line.strip() for line in kek]\n",
    "for line in lines:\n",
    "    if i < 100:\n",
    "        print(line)\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                                                                             #\n",
    "#                             VALUE & UPDATE                                  #\n",
    "#                                                                             #\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "class Value:\n",
    "    \"\"\"\n",
    "    Dense object that holds parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n):\n",
    "        ...\n",
    "\n",
    "    def dot(self, update):\n",
    "        ...\n",
    "\n",
    "    def assign(self, other):\n",
    "        \"\"\"\n",
    "        self = other\n",
    "        other is Value.\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    def assign_mul(self, coeff):\n",
    "        \"\"\"\n",
    "        self = self * coeff\n",
    "        coeff is float.\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    def assign_madd(self, x, coeff):\n",
    "        \"\"\"\n",
    "        self = self + x * coeff\n",
    "        x can be either Value or Update.\n",
    "        coeff is float.\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "class Update:\n",
    "    \"\"\"\n",
    "    Sparse object that holds an update of parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, positions=None, values=None):\n",
    "        \"\"\"\n",
    "        positions: array of int\n",
    "        values: array of float\n",
    "        \"\"\"\n",
    "\n",
    "    def assign_mul(self, coeff):\n",
    "        \"\"\"\n",
    "        self = self * coeff\n",
    "        coeff: float\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    def assign_madd(self, update, coeff):\n",
    "        \"\"\"\n",
    "        self = self + update * coeff\n",
    "        coeff: float\n",
    "        \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "#                                                                             #\n",
    "#                                  MODEL                                      #\n",
    "#                                                                             #\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "Features = Update\n",
    "\n",
    "\n",
    "class LinearModel:\n",
    "    \"\"\"\n",
    "    A thing that computes score and gradient for given features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n):\n",
    "        self._params = Value(n)\n",
    "\n",
    "    def params(self):\n",
    "        return self._params\n",
    "\n",
    "    def score(self, features):\n",
    "        \"\"\"\n",
    "        features: Update\n",
    "        \"\"\"\n",
    "        return self._params.dot(features)\n",
    "\n",
    "    def gradient(self, features, score):\n",
    "        return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "#                                                                             #\n",
    "#                                    HYPO                                     #\n",
    "#                                                                             #\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "Hypo = collections.namedtuple('Hypo', ['prev', 'pos', 'tagged_word', 'score'])\n",
    "# prev: previous Hypo\n",
    "# pos: position of word (0-based)\n",
    "# tagged_word: tagging of source_sentence[pos]\n",
    "# score: sum of scores over edges\n",
    "\n",
    "###############################################################################\n",
    "#                                                                             #\n",
    "#                              FEATURE COMPUTER                               #\n",
    "#                                                                             #\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def h(x):\n",
    "    \"\"\"\n",
    "    Compute CityHash of any object.\n",
    "    Can be used to construct features.\n",
    "    \"\"\"\n",
    "    return cityhash.CityHash64(repr(x))\n",
    "\n",
    "\n",
    "TaggerParams = collections.namedtuple('FeatureParams', [\n",
    "    'src_window',\n",
    "    'dst_order',\n",
    "    'max_suffix',\n",
    "    'beam_size',\n",
    "    'nparams'\n",
    "    ])\n",
    "\n",
    "\n",
    "class FeatureComputer:\n",
    "    def __init__(self, tagger_params, source_sentence):\n",
    "        ...\n",
    "\n",
    "    def compute_features(self, hypo):\n",
    "        \"\"\"\n",
    "        Compute features for a given Hypo and return Update.\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "#                                                                             #\n",
    "#                                BEAM SEARCH                                  #\n",
    "#                                                                             #\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "class BeamSearchTask:\n",
    "    \"\"\"\n",
    "    An abstract beam search task. Can be used with beam_search() generic \n",
    "    function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tagger_params, source_sentence, model, tags):\n",
    "        ...\n",
    "\n",
    "    def total_num_steps(self):\n",
    "        \"\"\"\n",
    "        Number of hypotheses between beginning and end (number of words in\n",
    "        the sentence).\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    def beam_size(self):\n",
    "        ...\n",
    "\n",
    "    def expand(self, hypo):\n",
    "        \"\"\"\n",
    "        Given Hypo, return a list of its possible expansions.\n",
    "        'hypo' might be None -- return a list of initial hypos then.\n",
    "\n",
    "        Compute hypotheses' scores inside this function!\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "    def recombo_hash(self, hypo):\n",
    "        \"\"\"\n",
    "        If two hypos have the same recombination hashes, they can be collapsed\n",
    "        together, leaving only the hypothesis with a better score.\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "def beam_search(beam_search_task):\n",
    "    \"\"\"\n",
    "    Return list of stacks.\n",
    "    Each stack contains several hypos, sorted by score in descending \n",
    "    order (i.e. better hypos first).\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "#                                                                             #\n",
    "#                            OPTIMIZATION TASKS                               #\n",
    "#                                                                             #\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "class OptimizationTask:\n",
    "    \"\"\"\n",
    "    Optimization task that can be used with sgd().\n",
    "    \"\"\"\n",
    "\n",
    "    def params(self):\n",
    "        \"\"\"\n",
    "        Parameters which are optimized in this optimization task.\n",
    "        Return Value.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def loss_and_gradient(self, golden_sentence):\n",
    "        \"\"\"\n",
    "        Return (loss, gradient) on a specific example.\n",
    "\n",
    "        loss: float\n",
    "        gradient: Update\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class UnstructuredPerceptronOptimizationTask(OptimizationTask):\n",
    "    def __init__(self, ...):\n",
    "        ...\n",
    "\n",
    "    def params(self):\n",
    "        ...\n",
    "\n",
    "    def loss_and_gradient(self, golden_sentence):\n",
    "        ...\n",
    "\n",
    "\n",
    "class StructuredPerceptronOptimizationTask(OptimizationTask):\n",
    "    def __init__(self, tagger_params, tags):\n",
    "        self.tagger_params = tagger_params\n",
    "        self.model = LinearModel(...)\n",
    "        self.tags = tags\n",
    "\n",
    "    def params(self):\n",
    "        return self.model.params()\n",
    "\n",
    "    def loss_and_gradient(self, golden_sentence):\n",
    "        # Do beam search.\n",
    "        beam_search_task = BeamSearchTask(\n",
    "            self.tagger_params, \n",
    "            [golden_tagged_word.text for golden_tagged_word in golden_sentence], \n",
    "            self.model, \n",
    "            self.tags\n",
    "            )\n",
    "        stacks = beam_search(beam_search_task)\n",
    "\n",
    "        # Compute chain of golden hypos (and their scores!).\n",
    "        golden_hypo = None\n",
    "        feature_computer = ...\n",
    "        for i in range(len(golden_sentence)):\n",
    "            new_golden_hypo = ...\n",
    "            golden_hypo = golden_hypo\n",
    "\n",
    "        # Find where to update.\n",
    "        golden_head = ...\n",
    "        rival_head = ...\n",
    "\n",
    "        # Compute gradient.\n",
    "        grad = Update()\n",
    "        while golden_head and rival_head:\n",
    "            rival_features = feature_computer.compute_features(rival_head)\n",
    "            grad.assign_madd(self.model.gradient(rival_features, score=None), 1)\n",
    "\n",
    "            golden_features = feature_computer.compute_features(golden_head)\n",
    "            grad.assign_madd(self.model.gradient(golden_features, score=None), -1)\n",
    "\n",
    "\n",
    "            golden_head = golden_head.prev\n",
    "            rival_head = rival_head.prev\n",
    "\n",
    "        return grad\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "#                                                                             #\n",
    "#                                    SGD                                      #\n",
    "#                                                                             #\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "SGDParams = collections.namedtuple('SGDParams', [\n",
    "    'epochs',\n",
    "    'learning_rate',\n",
    "    'minibatch_size',\n",
    "    'average' # bool or int\n",
    "    ])\n",
    "\n",
    "\n",
    "def make_batches(dataset, minibatch_size):\n",
    "    \"\"\"\n",
    "    Make list of batches from a list of examples.\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "\n",
    "def sgd(sgd_params, optimization_task, dataset, after_each_epoch_fn):\n",
    "    \"\"\"\n",
    "    Run (averaged) SGD on a generic optimization task. Modify optimization\n",
    "    task's parameters.\n",
    "\n",
    "    After each epoch (and also before and after the whole training),\n",
    "    run after_each_epoch_fn().\n",
    "    \"\"\"\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "#                                                                             #\n",
    "#                                    MAIN                                     #\n",
    "#                                                                             #\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "# - Train - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "\n",
    "def TRAIN_add_cmdargs(subp):\n",
    "    p = subp.add_parser('train')\n",
    "\n",
    "    p.add_argument('--tags',\n",
    "        help='tags file', type=str, default='data/tags')\n",
    "    p.add_argument('--dataset',\n",
    "        help='train dataset', default='data/en-ud-train.conllu')\n",
    "    p.add_argument('--dataset-dev',\n",
    "        help='dev dataset', default='data/en-ud-dev.conllu')\n",
    "    p.add_argument('--model',\n",
    "        help='NPZ model', type=str, default='model.npz')\n",
    "    p.add_argument('--sgd-epochs',\n",
    "        help='SGD number of epochs', type=int, default=15)\n",
    "    p.add_argument('--sgd-learning-rate',\n",
    "        help='SGD learning rate', type=float, default=0.01)\n",
    "    p.add_argument('--sgd-minibatch-size',\n",
    "        help='SGD minibatch size (in sentences)', type=int, default=32)\n",
    "    p.add_argument('--sgd-average',\n",
    "        help='SGD average every N batches', type=int, default=32)\n",
    "    p.add_argument('--tagger-src-window',\n",
    "        help='Number of context words in input sentence to use for features',\n",
    "        type=int, default=2)\n",
    "    p.add_argument('--tagger-dst-order',\n",
    "        help='Number of context tags in output tagging to use for features',\n",
    "        type=int, default=3)\n",
    "    p.add_argument('--tagger-max-suffix',\n",
    "        help='Maximal number of prefix/suffix letters to use for features',\n",
    "        type=int, default=4)\n",
    "    p.add_argument('--beam-size',\n",
    "        help='Beam size (0 means unstructured)', type=int, default=1)\n",
    "    p.add_argument('--nparams',\n",
    "        help='Parameter vector size', type=int, default=2**22)\n",
    "\n",
    "    return 'train'\n",
    "\n",
    "def TRAIN(cmdargs):\n",
    "    # Beam size.\n",
    "    optimization_task_cls = StructuredPerceptronOptimizationTask\n",
    "    if cmdargs.beam_size == 0:\n",
    "        cmdargs.beam_size = 1\n",
    "        optimization_task_cls = UnstructuredPerceptronOptimizationTask\n",
    "\n",
    "    # Parse cmdargs.\n",
    "    tags = read_tags(cmdargs.tags)\n",
    "    dataset = read_tagged_sentences(cmdargs.dataset)\n",
    "    dataset_dev = read_tagged_sentences(cmdargs.dataset_dev)\n",
    "    params = None\n",
    "    if os.path.exists(cmdargs.model):\n",
    "        params = pickle.load(open(cmdargs.model, 'rb'))\n",
    "    sgd_params = SGDParams(\n",
    "        epochs=cmdargs.sgd_epochs,\n",
    "        learning_rate=cmdargs.sgd_learning_rate,\n",
    "        minibatch_size=cmdargs.sgd_minibatch_size,\n",
    "        average=cmdargs.sgd_average\n",
    "        )\n",
    "    tagger_params = TaggerParams(\n",
    "        src_window=cmdargs.tagger_src_window,\n",
    "        dst_order=cmdargs.tagger_dst_order,\n",
    "        max_suffix=cmdargs.tagger_max_suffix,\n",
    "        beam_size=cmdargs.beam_size,\n",
    "        nparams=cmdargs.nparams\n",
    "        )\n",
    "\n",
    "    # Load optimization task\n",
    "    optimization_task = optimization_task_cls(...)\n",
    "    if params is not None:\n",
    "        print('\\n\\nLoading parameters from %s\\n\\n' % cmdargs.model)\n",
    "        optimization_task.params().assign(params)\n",
    "\n",
    "    # Validation.\n",
    "    def after_each_epoch_fn():\n",
    "        model = LinearModel(cmdargs.nparams)\n",
    "        model.params().assign(optimization_task.params())\n",
    "        tagged_sentences = tag_sentences(dataset_dev, ...)\n",
    "        q = pprint.pformat(tagging_quality(out=tagged_sentences, ref=dataset_dev))\n",
    "        print()\n",
    "        print(q)\n",
    "        print()\n",
    "\n",
    "        # Save parameters.\n",
    "        print('\\n\\nSaving parameters to %s\\n\\n' % cmdargs.model)\n",
    "        pickle.dump(optimization_task.params(), open(cmdargs.model, 'wb'))\n",
    "\n",
    "    # Run SGD.\n",
    "    sgd(sgd_params, optimization_task, dataset, after_each_epoch_fn)\n",
    "\n",
    "\n",
    "# - Test  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "\n",
    "def TEST_add_cmdargs(subp):\n",
    "    p = subp.add_parser('test')\n",
    "\n",
    "    p.add_argument('--tags',\n",
    "        help='tags file', type=str, default='data/tags')\n",
    "    p.add_argument('--dataset',\n",
    "        help='test dataset', default='data/en-ud-dev.conllu')\n",
    "    p.add_argument('--model',\n",
    "        help='NPZ model', type=str, default='model.npz')\n",
    "    p.add_argument('--tagger-src-window',\n",
    "        help='Number of context words in input sentence to use for features',\n",
    "        type=int, default=2)\n",
    "    p.add_argument('--tagger-dst-order',\n",
    "        help='Number of context tags in output tagging to use for features',\n",
    "        type=int, default=3)\n",
    "    p.add_argument('--tagger-max-suffix',\n",
    "        help='Maximal number of prefix/suffix letters to use for features',\n",
    "        type=int, default=4)\n",
    "    p.add_argument('--beam-size',\n",
    "        help='Beam size', type=int, default=1)\n",
    "\n",
    "    return 'test'\n",
    "\n",
    "\n",
    "def tag_sentences(dataset, ...):\n",
    "    \"\"\"\n",
    "    Tag all sentences in dataset. Dataset is a list of TaggedSentence; while \n",
    "    tagging, ignore existing tags.\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "\n",
    "def TEST(cmdargs):\n",
    "    # Parse cmdargs.\n",
    "    tags = read_tags(cmdargs.tags)\n",
    "    dataset = read_tagged_sentences(cmdargs.dataset)\n",
    "    params = pickle.load(open(cmdargs.model, 'rb'))\n",
    "    tagger_params = TaggerParams(\n",
    "        src_window=cmdargs.tagger_src_window,\n",
    "        dst_order=cmdargs.tagger_dst_order,\n",
    "        max_suffix=cmdargs.tagger_max_suffix,\n",
    "        beam_size=cmdargs.beam_size,\n",
    "        nparams=0\n",
    "        )\n",
    "\n",
    "    # Load model.\n",
    "    model = LinearModel(params.values.shape[0])\n",
    "    model.params().assign(params)\n",
    "\n",
    "    # Tag all sentences.\n",
    "    tagged_sentences = tag_sentences(dataset, ...)\n",
    "\n",
    "    # Write tagged sentences.\n",
    "    for tagged_sentence in tagged_sentences:\n",
    "        write_tagged_sentence(tagged_sentence, sys.stdout)\n",
    "\n",
    "    # Measure and print quality.\n",
    "    q = pprint.pformat(tagging_quality(out=tagged_sentences, ref=dataset))\n",
    "    print(q, file=sys.stderr)\n",
    "\n",
    "\n",
    "# - Main  - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Create parser.\n",
    "    p = argparse.ArgumentParser('tagger.py')\n",
    "    subp = p.add_subparsers(dest='cmd')\n",
    "\n",
    "    # Add subcommands.\n",
    "    train = TRAIN_add_cmdargs(subp)\n",
    "    test = TEST_add_cmdargs(subp)\n",
    "\n",
    "    # Parse.\n",
    "    cmdargs = p.parse_args()\n",
    "\n",
    "    # Run.\n",
    "    if cmdargs.cmd == train:\n",
    "        TRAIN(cmdargs)\n",
    "    elif cmdargs.cmd == test:\n",
    "        TEST(cmdargs)\n",
    "    else:\n",
    "        p.error('No command')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
