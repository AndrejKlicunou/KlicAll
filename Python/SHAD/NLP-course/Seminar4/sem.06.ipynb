{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Контекстно-свободные грамматики  \n",
    "Курс NLP, семинар 11.  \n",
    "Осень 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подпись: (введите сюда свои ФИО + отделение + курс)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://i.imgur.com/XLREeKo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Немного теории\n",
    "\n",
    "*Формальная грамматика* (определение с лекции):\n",
    " - конечное множество нетерминалов $P$;\n",
    " - конечное множество терминалов $\\Sigma$;\n",
    " - конечное множество продукций $P$, каждая из которых имеет вид\n",
    " \n",
    "$$(\\Sigma \\cup N)^∗ N (\\Sigma \\cup N)^∗ \\rightarrow (\\Sigma \\cup N)^∗$$\n",
    " - начальный нетерминал $S$.\n",
    " \n",
    "*Контекстно-свободная грамматика* имеет правила вида $A \\rightarrow \\beta, \\beta \\in (N \\cup \\Sigma)^*$.\n",
    "\n",
    "\n",
    "Контекстно-свободная является грамматикой в *нормальной форме Хомского*, если содержит только правила вида: \n",
    " - $A \\rightarrow B C$\n",
    " - $A \\rightarrow a$\n",
    " - $S \\rightarrow \\varepsilon$\n",
    "\n",
    "где $a$ $-$ терминал, $A, B, C$ $-$ нетерминалы, $S$ $-$ начальный нетерминал не содержащийся в правых частях правил, $\\varepsilon$ $-$ пустая строка.\n",
    "\n",
    "Как привести грамматику к нормальной форме Хомского можно прочитать [здесь](http://math.stackexchange.com/questions/296243/converting-to-chomsky-normal-form) или [здесь](http://neerc.ifmo.ru/wiki/index.php?title=Нормальная_форма_Хомского#.D0.9F.D1.80.D0.B8.D0.B2.D0.B5.D0.B4.D0.B5.D0.BD.D0.B8.D0.B5_.D0.B3.D1.80.D0.B0.D0.BC.D0.BC.D0.B0.D1.82.D0.B8.D0.BA.D0.B8_.D0.BA_.D0.BD.D0.BE.D1.80.D0.BC.D0.B0.D0.BB.D1.8C.D0.BD.D0.BE.D0.B9_.D1.84.D0.BE.D1.80.D0.BC.D0.B5_.D0.A5.D0.BE.D0.BC.D1.81.D0.BA.D0.BE.D0.B3.D0.BE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chomsky Normal Form \n",
    "Приведите грамматику к нормальной форме Хомского (и выпишите итоговую <font color='red'>внутри ipython ноутбука</font>):\n",
    "\n",
    "- $S \\rightarrow NP ~~ VP$\n",
    "- $NP \\rightarrow DET ~~ ADJ ~~ N \\mid NN$\n",
    "- $VP \\rightarrow V ~~ NP \\mid VP ~~ PP \\mid V$\n",
    "- $DET \\rightarrow a$\n",
    "- $ADJ \\rightarrow tasty \\mid ADV ~~ ADJ \\mid \\epsilon$\n",
    "- $ADV \\rightarrow very$\n",
    "- $N \\rightarrow fish \\mid fork \\mid dog \\mid boy$\n",
    "- $NN \\rightarrow Mary \\mid John$\n",
    "- $V \\rightarrow eats$\n",
    "- $PP \\rightarrow P ~~ NP \\mid \\epsilon$\n",
    "- $P \\rightarrow with$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CYK Parser\n",
    "\n",
    "Реализуйте синтаксический парсер, работающий по методу [**CYK**](https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%9A%D0%BE%D0%BA%D0%B0_%E2%80%94_%D0%AF%D0%BD%D0%B3%D0%B5%D1%80%D0%B0_%E2%80%94_%D0%9A%D0%B0%D1%81%D0%B0%D0%BC%D0%B8) и выполняющий функцию проверки принадлежности строки грамматике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "class CYKParser:\n",
    "    def __init__(self, rules):\n",
    "        self.rules = rules\n",
    "        \n",
    "    def get_non_terminals_dict(self):\n",
    "        non_terminals_dict = {}\n",
    "        i = 0\n",
    "        for start in list(sorted(self.rules.keys())):\n",
    "            if start not in non_terminals_dict:\n",
    "                non_terminals_dict[start] = i\n",
    "                i += 1\n",
    "            for end in self.rules[start]:\n",
    "                parts = end.split(' ')\n",
    "                if len(parts) == 2:\n",
    "                    for part in parts:\n",
    "                        if part not in non_terminals_dict:\n",
    "                            non_terminals_dict[part] = i\n",
    "                            i += 1\n",
    "        return non_terminals_dict\n",
    "    \n",
    "    def parse(self, in_tokens):\n",
    "        ntd = self.get_non_terminals_dict()\n",
    "        p = []\n",
    "        for i in range(len(in_tokens)):\n",
    "            p.append([])\n",
    "            for j in range(len(in_tokens)):\n",
    "                p[i].append([])\n",
    "                for k in range(len(ntd)):\n",
    "                    p[i][j].append(False)\n",
    "        for i in range(len(in_tokens)):\n",
    "            word = in_tokens[i]\n",
    "            for start in self.rules.keys():\n",
    "                for end in self.rules[start]:\n",
    "                    if len(end.split(' ')) == 1:\n",
    "                        if end == word:\n",
    "                            p[0][i][ntd[start]] = True\n",
    "        for i in range(2, len(in_tokens) + 1):\n",
    "            for j in range(1, len(in_tokens) - i + 2):\n",
    "                for k in range(1, i):\n",
    "                    for start in self.rules.keys():\n",
    "                        for end in self.rules[start]:\n",
    "                            parts = end.split(' ')\n",
    "                            if len(parts) == 2:\n",
    "                                if p[k-1][j-1][ntd[parts[0]]] and p[i - k - 1][j + k - 1][ntd[parts[1]]]:\n",
    "                                    p[i-1][j-1][ntd[start]] = True\n",
    "        return p[len(in_tokens) - 1][0][ntd['S']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введите сюда полученную грамматику из первого пункта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULES = {\n",
    "    'S': ['NP VP'],\n",
    "    ### YOUR GRAMMAR IN CNF HERE\n",
    "    'NP': ['Mary', 'John', 'DET T_NP', 'DET N', ],\n",
    "    'T_NP': ['ADJ N', 'ADV N'],\n",
    "    'VP': ['V NP', 'VP PP', 'VP V', 'VP VP'],\n",
    "    'DET': ['a'],\n",
    "    'ADJ': ['tasty', 'ADV ADJ', 'ADV ADV'],\n",
    "    'ADV': ['very'],\n",
    "    'N': ['fish', 'fork', 'dog', 'boy'],\n",
    "    'NN': [],\n",
    "    'V': ['eats'],\n",
    "    'PP': ['P NP'],\n",
    "    'P': ['with'],\n",
    "    ### END OF YOUR GRAMMAR\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ': 0,\n",
       " 'ADV': 1,\n",
       " 'DET': 2,\n",
       " 'N': 3,\n",
       " 'NN': 4,\n",
       " 'NP': 5,\n",
       " 'P': 7,\n",
       " 'PP': 8,\n",
       " 'S': 9,\n",
       " 'T_NP': 6,\n",
       " 'V': 11,\n",
       " 'VP': 10}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kek = CYKParser(RULES)\n",
    "#print(kek.get)\n",
    "kek.get_non_terminals_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ': 1,\n",
       " 'ADV': 3,\n",
       " 'Det': 8,\n",
       " 'EPS': 11,\n",
       " 'N': 2,\n",
       " 'NN': 9,\n",
       " 'NP': 5,\n",
       " 'P': 10,\n",
       " 'PP': 12,\n",
       " 'S': 4,\n",
       " 'TEMP': 0,\n",
       " 'V': 7,\n",
       " 'VP': 6}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kek.get_non_terminals_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время проверить нашу грамматику."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positve examples:\n",
      "-------------------------------------------------------------\n",
      "OK! Mary eats a fish\n",
      "OK! John eats a very very very tasty fish with a fork\n",
      "OK! a dog eats a boy\n",
      "OK! Mary eats John with a fork\n",
      "OK! John eats a fork\n",
      "OK! a very fish eats Mary\n",
      "*************************************************************\n",
      "Negative examples:\n",
      "-------------------------------------------------------------\n",
      "OK! John\n",
      "OK! Mary eats a eats\n",
      "OK! boy eats dog\n",
      "OK! John eats a very very very tasty fish with fork\n",
      "OK! a Mary fork\n",
      "OK! eats\n",
      "OK! a\n",
      "*************************************************************\n"
     ]
    }
   ],
   "source": [
    "correct_sentences = [\n",
    "    'Mary eats a fish',\n",
    "    'John eats a very very very tasty fish with a fork',\n",
    "    'a dog eats a boy',\n",
    "    'Mary eats John with a fork',\n",
    "    'John eats a fork',\n",
    "    'a very fish eats Mary'\n",
    "]\n",
    "\n",
    "not_correct_sentences = [\n",
    "    'John',\n",
    "    'Mary eats a eats',\n",
    "    'boy eats dog',\n",
    "    'John eats a very very very tasty fish with fork',\n",
    "    'a Mary fork',\n",
    "    'eats',\n",
    "    'a'\n",
    "]\n",
    "\n",
    "parser = CYKParser(RULES)\n",
    "print('Positve examples:')\n",
    "print('-------------------------------------------------------------')\n",
    "for sentence in correct_sentences:\n",
    "    if parser.parse(sentence.split()):\n",
    "        print('OK!', sentence)\n",
    "    else:\n",
    "        print('ERROR!', sentence)\n",
    "print('*************************************************************')\n",
    "print('Negative examples:')  \n",
    "print('-------------------------------------------------------------')\n",
    "for sentence in not_correct_sentences:\n",
    "    if not parser.parse(sentence.split()):\n",
    "        print('OK!', sentence)\n",
    "    else:\n",
    "        print('ERROR!', sentence)\n",
    "print('*************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extended CYK Parser \n",
    "\n",
    "Модифицируйте парсер так, чтобы он возвращал цепочку правил, составляющих разбор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "\n",
    "class CYKParser:\n",
    "    def __init__(self, rules):\n",
    "        self.rules = rules\n",
    "    \n",
    "    \n",
    "    def get_non_terminals_dict(self):\n",
    "        non_terminals_dict = {}\n",
    "        i = 0\n",
    "        for start in list(sorted(self.rules.keys())):\n",
    "            if start not in non_terminals_dict:\n",
    "                non_terminals_dict[start] = i\n",
    "                i += 1\n",
    "            for end in self.rules[start]:\n",
    "                parts = end.split(' ')\n",
    "                if len(parts) == 2:\n",
    "                    for part in parts:\n",
    "                        if part not in non_terminals_dict:\n",
    "                            non_terminals_dict[part] = i\n",
    "                            i += 1\n",
    "        return non_terminals_dict\n",
    "    \n",
    "    \n",
    "    def convert_rule_to_text(self, rule):\n",
    "        return rule[0] + ' -> ' + ' '.join(rule[1:])\n",
    "    \n",
    "    \n",
    "    def get_chain(self, r_mem, k_mem, i, j, nt_id):\n",
    "        r = r_mem[i-1][j-1][nt_id]\n",
    "        if len(r) == 2:\n",
    "            return [self.convert_rule_to_text(r)]\n",
    "        else:\n",
    "            k = k_mem[i-1][j-1][nt_id]\n",
    "            return [self.convert_rule_to_text(r)] + \\\n",
    "                    self.get_chain(r_mem, k_mem, k, j, self.get_non_terminals_dict()[r[1]]) + \\\n",
    "                    self.get_chain(r_mem, k_mem, i-k, j+k, self.get_non_terminals_dict()[r[2]])\n",
    "    \n",
    "    \n",
    "    def parse(self, in_tokens):\n",
    "        ntd = self.get_non_terminals_dict()\n",
    "        p = []\n",
    "        r_mem = []\n",
    "        k_mem = []\n",
    "        for i in range(len(in_tokens)):\n",
    "            p.append([])\n",
    "            r_mem.append([])\n",
    "            k_mem.append([])\n",
    "            for j in range(len(in_tokens)):\n",
    "                p[i].append([])\n",
    "                r_mem[i].append([])\n",
    "                k_mem[i].append([])\n",
    "                for k in range(len(ntd)):\n",
    "                    p[i][j].append(False)\n",
    "                    r_mem[i][j].append([])\n",
    "                    k_mem[i][j].append([])\n",
    "        for i in range(len(in_tokens)):\n",
    "            word = in_tokens[i]\n",
    "            for start in self.rules.keys():\n",
    "                for end in self.rules[start]:\n",
    "                    if len(end.split(' ')) == 1:\n",
    "                        if end == word:\n",
    "                            p[0][i][ntd[start]] = True\n",
    "                            r_mem[0][i][ntd[start]] = [start, word]\n",
    "        for i in range(2, len(in_tokens) + 1):\n",
    "            for j in range(1, len(in_tokens) - i + 2):\n",
    "                for k in range(1, i):\n",
    "                    for start in self.rules.keys():\n",
    "                        for end in self.rules[start]:\n",
    "                            parts = end.split(' ')\n",
    "                            if len(parts) == 2:\n",
    "                                if p[k-1][j-1][ntd[parts[0]]] and p[i - k - 1][j + k - 1][ntd[parts[1]]]:\n",
    "                                    p[i-1][j-1][ntd[start]] = True\n",
    "                                    r_mem[i-1][j-1][ntd[start]] = [start] + parts\n",
    "                                    k_mem[i-1][j-1][ntd[start]] = k\n",
    "        if p[len(in_tokens) - 1][0][ntd['S']]:\n",
    "            return [self.get_chain(r_mem, k_mem, len(in_tokens), 1, ntd['S'])]\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 1 9\n",
      "1 1 5\n",
      "10 2 10\n",
      "7 2 10\n",
      "1 2 11\n",
      "6 3 5\n",
      "1 3 2\n",
      "5 4 6\n",
      "4 4 0\n",
      "1 4 1\n",
      "3 5 0\n",
      "1 5 1\n",
      "2 6 0\n",
      "1 6 1\n",
      "1 7 0\n",
      "1 8 3\n",
      "3 9 8\n",
      "1 9 7\n",
      "2 10 5\n",
      "1 10 2\n",
      "1 11 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['S -> NP VP',\n",
       "  'NP -> John',\n",
       "  'VP -> VP PP',\n",
       "  'VP -> V NP',\n",
       "  'V -> eats',\n",
       "  'NP -> DET T_NP',\n",
       "  'DET -> a',\n",
       "  'T_NP -> ADJ N',\n",
       "  'ADJ -> ADV ADJ',\n",
       "  'ADV -> very',\n",
       "  'ADJ -> ADV ADJ',\n",
       "  'ADV -> very',\n",
       "  'ADJ -> ADV ADJ',\n",
       "  'ADV -> very',\n",
       "  'ADJ -> tasty',\n",
       "  'N -> fish',\n",
       "  'PP -> P NP',\n",
       "  'P -> with',\n",
       "  'NP -> DET N',\n",
       "  'DET -> a',\n",
       "  'N -> fork']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CYKParser(RULES).parse('John eats a very very very tasty fish with a fork'.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S -> NP VP\n",
      "NP -> Mary\n",
      "VP -> V NP\n",
      "V -> eats\n",
      "NP -> DET N\n",
      "DET -> a\n",
      "N -> fish\n",
      "\n",
      "S -> NP VP\n",
      "NP -> John\n",
      "VP -> VP PP\n",
      "VP -> V NP\n",
      "V -> eats\n",
      "NP -> DET T_NP\n",
      "DET -> a\n",
      "T_NP -> ADJ N\n",
      "ADJ -> ADV ADJ\n",
      "ADV -> very\n",
      "ADJ -> ADV ADJ\n",
      "ADV -> very\n",
      "ADJ -> ADV ADJ\n",
      "ADV -> very\n",
      "ADJ -> tasty\n",
      "N -> fish\n",
      "PP -> P NP\n",
      "P -> with\n",
      "NP -> DET N\n",
      "DET -> a\n",
      "N -> fork\n",
      "\n",
      "S -> NP VP\n",
      "NP -> DET N\n",
      "DET -> a\n",
      "N -> dog\n",
      "VP -> V NP\n",
      "V -> eats\n",
      "NP -> DET N\n",
      "DET -> a\n",
      "N -> boy\n",
      "\n",
      "S -> NP VP\n",
      "NP -> Mary\n",
      "VP -> VP PP\n",
      "VP -> V NP\n",
      "V -> eats\n",
      "NP -> John\n",
      "PP -> P NP\n",
      "P -> with\n",
      "NP -> DET N\n",
      "DET -> a\n",
      "N -> fork\n",
      "\n",
      "S -> NP VP\n",
      "NP -> John\n",
      "VP -> V NP\n",
      "V -> eats\n",
      "NP -> DET N\n",
      "DET -> a\n",
      "N -> fork\n",
      "\n",
      "S -> NP VP\n",
      "NP -> DET T_NP\n",
      "DET -> a\n",
      "T_NP -> ADV N\n",
      "ADV -> very\n",
      "N -> fish\n",
      "VP -> V NP\n",
      "V -> eats\n",
      "NP -> Mary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in correct_sentences:\n",
    "    for chain in CYKParser(RULES).parse(sent.split()):\n",
    "        for rule in chain:\n",
    "            print(rule)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вместо заключения \n",
    "\n",
    "Вспомним про nltk и Earley парсер. Грамматики тут задаются следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det ADJ N | NN\n",
    "    VP -> V NP | VP PP | V\n",
    "    Det -> 'a'\n",
    "    ADJ -> 'tasty' | ADV ADJ | \n",
    "    ADV -> 'very'\n",
    "    N -> 'fish' | 'fork' | 'dog' | 'boy'\n",
    "    NN -> 'Mary' | 'John'\n",
    "    V -> 'eats'\n",
    "    PP -> P NP | \n",
    "    P -> 'with'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим парсер и применим к предложению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.EarleyChartParser(grammar)\n",
    "trees = list(parser.parse('a very fish eats Mary'.split()))\n",
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы увидеть сам разбор, достаточно установить параметр *trace* у парсера (по умолчанию trace=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = nltk.EarleyChartParser(grammar, trace=1)\n",
    "trees = parser.parse('Mary eats a fish'.split())\n",
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = nltk.EarleyChartParser(grammar, trace=2)\n",
    "trees = parser.parse('John eats a very very very tasty fish with a fork'.split())\n",
    "for tree in trees:\n",
    "    print(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
