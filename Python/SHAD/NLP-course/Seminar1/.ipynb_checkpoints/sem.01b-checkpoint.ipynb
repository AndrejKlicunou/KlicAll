{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Элементарная обработка текста\n",
    "Автоматическая обработка текстов - 2017, семинар 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе вам будет предложено провести элементарную обработку текста. Для работы понадобится текст книги (возьмите на вики)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length (in symbols) = 1000043\n"
     ]
    }
   ],
   "source": [
    "# Let's read the book\n",
    "corpus = None\n",
    "corpus_name = 'Fellowship_of_the_Ring.txt'\n",
    "with open(corpus_name) as fin:\n",
    "    corpus = fin.read()\n",
    "print('Corpus length (in symbols) = {}'.format(len(corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала просто разобьем текст на слова. Словом мы называем последовательность латинских символов, разделенных чем-то кроме букв. Попробуем стандартный питоновский **split**. Разделите текст по пробелам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length (in words) = 183746\n",
      "['John', 'R.', 'R.', 'TolkienForeword\\n\\nPrologue1.', 'Concerning', 'Hobbits\\n\\n2.', 'Concerning', 'Pipe-weed\\n\\n3.', 'Of', 'the', 'Ordering', 'of', 'the', 'Shire\\n\\n4.', 'Of', 'the', 'Finding', 'of', 'the', 'Ring\\n\\n\\n\\n\\n\\nBook', 'IChapter', '1\\n\\nChapter', '2\\n\\nChapter', '3\\n\\nChapter', '4\\n\\nChapter', '5\\n\\nChapter', '6\\n\\nChapter', '7\\n\\nChapter', '8\\n\\nChapter', '9\\n\\nChapter', '10\\n\\nChapter', '11\\n\\nChapter', '12\\n\\n\\n\\n\\n\\nBook', 'IIChapter', '1\\n\\nChapter', '2\\n\\nChapter', '3\\n\\nChapter', '4\\n\\nChapter', '5\\n\\nChapter', '6\\n\\nChapter', '7\\n\\nChapter', '8\\n\\nChapter', '9\\n\\nChapter', '10\\n\\n\\n\\n\\n\\nnotes1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n\\n\\n\\n\\n*', '*', '*\\n\\n\\n\\n\\n\\nJohn', 'R.', 'R.', 'Tolkien\\n\\nFellowship', 'of']\n"
     ]
    }
   ],
   "source": [
    "# Split corpus into words using split() function.\n",
    "words = corpus.split(' ')\n",
    "\n",
    "print('Corpus length (in words) = {}'.format(len(words)))\n",
    "print(words[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, сюда попали и все знаки препинания. Во-вторых, **split** не удобен тем, что он не может разделять по нескольким символам. В этом случае на помощь нам приходит **re.split**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что такое re и чем он полезен?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module provides regular expression matching operations.\n",
    "\n",
    "Regular expressions can contain both special and ordinary characters.\n",
    "Most ordinary characters, like \"A\", \"a\", or \"0\", are the simplest\n",
    "regular expressions; they simply match themselves.  You can\n",
    "concatenate ordinary characters, so last matches the string 'last'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The special characters are:\n",
    "\n",
    "    \".\"      Matches any character except a newline.\n",
    "    \"*\"      Matches 0 or more (greedy) repetitions of the preceding RE.\n",
    "             Greedy means that it will match as many repetitions as possible.\n",
    "    \"+\"      Matches 1 or more (greedy) repetitions of the preceding RE.\n",
    "    \"?\"      Matches 0 or 1 (greedy) of the preceding RE.\n",
    "    \n",
    "    {m,n}    Matches from m to n repetitions of the preceding RE.\n",
    "    []       Indicates a set of characters.\n",
    "             A \"^\" as the first character indicates a complementing set.\n",
    "    \"|\"      A|B, creates an RE that will match either A or B.\n",
    "    (...)    Matches the RE inside the parentheses.\n",
    "             The contents can be retrieved or matched later in the string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The special sequences consist of \"\\\\\" and a character from the list\n",
    "below.  If the ordinary character is not on the list, then the\n",
    "resulting RE will match the second character.\n",
    "\n",
    "    \\d       Matches any decimal digit; equivalent to the set [0-9] in\n",
    "             bytes patterns or string patterns with the ASCII flag.\n",
    "    \\D       Matches any non-digit character; equivalent to [^\\d].\n",
    "    \\s       Matches any whitespace character; equivalent to [ \\t\\n\\r\\f\\v] in\n",
    "             bytes patterns or string patterns with the ASCII flag.\n",
    "    \\S       Matches any non-whitespace character; equivalent to [^\\s].\n",
    "    \\w       Matches any alphanumeric character; equivalent to [a-zA-Z0-9_]\n",
    "             in bytes patterns or string patterns with the ASCII flag.\n",
    "    \\W       Matches the complement of \\w.\n",
    "    \\\\       Matches a literal backslash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some re functions:\n",
    "\n",
    "    sub       Substitute occurrences of a pattern found in a string.\n",
    "    split     Split a string by the occurrences of a pattern.\n",
    "    findall   Find all occurrences of a pattern in a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See more in documentation: https://docs.python.org/3.5/library/re.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдём все числа в корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '1', '2', '3', '4', '5', '6', '7', '8', '1937', '1936', '1949', '1939', '1941', '1944', '1939', '1939', '1914', '1939', '1918', '1', '1', '2', '37', '1158']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall('[0-9]+', corpus)[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем найти в корпусе все \"даты\", то есть слова, состоящие из четырёх цифр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1937', '1936', '1949', '1939', '1941', '1944', '1939', '1939', '1914', '1939', '1918', '1158', '1147', '1070', '1462', '1341', '1342', '1401', '1420', '1592', '1403', '1418', '1418', '1311', '1600', '1451', '1462', '1482']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall('[0-9]{4}', corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь возьмём только даты между 1500 и 1999 годами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1937', '1936', '1949', '1939', '1941', '1944', '1939', '1939', '1914', '1939', '1918', '1592', '1600']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall('[1[5-9][0-9]{2}]', corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do it youself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите текст по _пробельным символам, точке, запятой, вопросительному знаку и восклицательному_, используя re.split().\n",
    "\n",
    "re.split(pattern, string, maxsplit=0, flags=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length (in words) = 217671\n",
      "['John', 'R', '', 'R', '', 'TolkienForeword', '', 'Prologue1', '', 'Concerning', 'Hobbits', '', '2', '', 'Concerning', 'Pipe-weed', '', '3', '', 'Of', 'the', 'Ordering', 'of', 'the', 'Shire', '', '4', '', 'Of', 'the', 'Finding', 'of', 'the', 'Ring', '', '', '', '', '', 'Book', 'IChapter', '1', '', 'Chapter', '2', '', 'Chapter', '3', '', 'Chapter']\n"
     ]
    }
   ],
   "source": [
    "# Split text into words using re.split() by ' ', '.', ',', '?', '!'.\n",
    "### YOUR CODE HERE\n",
    "words = re.split('[\\s.,?!]', corpus, maxsplit=0, flags=0)\n",
    "### END YOUR CODE\n",
    "\n",
    "print('Corpus length (in words) = {}'.format(len(words)))\n",
    "print(words[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы думаете, почему возникли пустые строки? (А если не возникли - молодцы! :) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте просто найдем все слова в тексте. Словом мы будем называть последовательность латинских символов, разделенных любыми иными знаками. Для этого воспользуйтесь **re.findall**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length (in words) = 189991\n"
     ]
    }
   ],
   "source": [
    "# It's your turn to split it into the separate words\n",
    "### YOUR CODE HERE\n",
    "words = re.findall('[a-zA-Z]+', corpus)\n",
    "### END YOUR CODE\n",
    "\n",
    "print('Corpus length (in words) = {}'.format(len(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Окей, отсортируем и посмотрим, что же у нас вышло."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n"
     ]
    }
   ],
   "source": [
    "# Now, let's sort all words in lexicographical order\n",
    "print(sorted(words)[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не очень впечатляет, не правда ли? Время поиспользовать питоновский [counter](https://docs.python.org/2/library/collections.html#collections.Counter). Добавьте слова в Counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 10707), ('and', 7131), ('of', 5040), ('to', 3902), ('a', 3544), ('I', 2836), ('in', 2772), ('was', 2461), ('that', 2382), ('he', 2291), ('it', 2163), ('you', 1585), ('they', 1540), ('his', 1502), ('said', 1479), ('not', 1379), ('is', 1316), ('for', 1273), ('as', 1271), ('had', 1257), ('on', 1228), ('Frodo', 1101), ('with', 1079), ('were', 1046), ('The', 1042), ('but', 1027), ('at', 1023), ('have', 1002), ('be', 890), ('him', 851), ('all', 799), ('them', 796), ('He', 749), ('But', 747), ('from', 734), ('we', 715), ('s', 684), ('or', 684), ('there', 681), ('are', 657), ('their', 656), ('if', 632), ('It', 622), ('out', 622), ('up', 597), ('now', 597), ('by', 559), ('will', 551), ('no', 539), ('this', 481)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "    \n",
    "word_counts = Counter()\n",
    "for word in words:\n",
    "    word_counts[word] += 1\n",
    "\n",
    "print(word_counts.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот и новые вопросы для раздумий:\n",
    "\n",
    "* Откуда взялись 's' и 'd'? К чему они относятся?\n",
    "* Подумайте, как бороться с подобными 's' и 'd'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но, как мы видим, не все так идеально. Например 'And' и 'and' являются разными словами. Приведите все к нижнему регистру и пересчитайте слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 11751), ('and', 7566), ('of', 5097), ('to', 3951), ('a', 3729), ('he', 3040), ('in', 2967), ('i', 2841), ('it', 2785), ('that', 2541)]\n",
      "Different words without lowering case: 9717\n",
      "Different words with lowering case: 8678\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "words_lower = []\n",
    "for word in words:\n",
    "    words_lower.append(word.lower())\n",
    "word_lower_counts = Counter(words_lower)\n",
    "### END YOUR CODE\n",
    "\n",
    "print(word_lower_counts.most_common(10))\n",
    "print('Different words without lowering case: {}'.format(len(word_counts)))\n",
    "print('Different words with lowering case: {}'.format(len(word_lower_counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<font color='red'>Вопросы на подумать:</font>\n",
    "\n",
    "* Приведите пример, когда два совершенно различных слова в итоге переходят в одно при приведении всего текста к нижнему регистру.\n",
    "* С какими еще проблемами мы можем столкнуться?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалите из Counter'a слова с частотой ниже 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of counter before deletions: 4379\n",
      "Size of counter after deletions: 4379\n",
      "Size of lowercase counter before deletions: 8678\n",
      "Size of lowercase counter after deletions: 4018\n"
     ]
    }
   ],
   "source": [
    "print('Size of counter before deletions: {}'.format(len(word_counts)))\n",
    "\n",
    "items = word_counts.items()\n",
    "nondeleted_items = []\n",
    "for i in items:\n",
    "    if i[1] >= 3:\n",
    "        nondeleted_items.append(i)\n",
    "word_counts = Counter(dict(nondeleted_items))\n",
    "\n",
    "print('Size of counter after deletions: {}'.format(len(word_counts)))\n",
    "\n",
    "print('Size of lowercase counter before deletions: {}'.format(len(word_lower_counts)))\n",
    "\n",
    "lower_items = word_lower_counts.items()\n",
    "lower_nondeleted_items = []\n",
    "for i in lower_items:\n",
    "    if i[1] >= 3:\n",
    "        lower_nondeleted_items.append(i)\n",
    "word_lower_counts = Counter(dict(lower_nondeleted_items))\n",
    "print('Size of lowercase counter after deletions: {}'.format(len(word_lower_counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Как сдавать\n",
    "\n",
    "В Контест нужно будет сдать файл **.py** со всеми необходимыми импортами и функцией *get_words_counter(corpus)*, которая возвращает *Counter* с парами (слово, сколько раз оно встретилось) для всех слов в тексте *corpus*, которые встретились хотя бы 3 раза.\n",
    "\n",
    "Тесты будут проверять две вещи:\n",
    "- похожи ли 20 самых частотных слов в вашем словаре на правильные?\n",
    "- а ещё вам нужно будет разобраться с отрицаниями: ведь если у вас среди токенов есть 'don' и 't' - это не очень правильно. Подумайте, как это было бы логично сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def get_words_counter(corpus):\n",
    "    nots_fixed_corpus = re.sub('[n][\\'][t]', '[\\s][n][o][t]', corpus, count=0, flags=0)\n",
    "    words = re.findall('[a-zA-Z]+', nots_fixed_corpus)\n",
    "    words_lower = []\n",
    "    for word in words:\n",
    "        words_lower.append(word.lower())\n",
    "    word_lower_counts = Counter(words_lower)\n",
    "    lower_items = word_lower_counts.items()\n",
    "    lower_nondeleted_items = []\n",
    "    for i in lower_items:\n",
    "        if i[1] >= 3:\n",
    "            lower_nondeleted_items.append(i)\n",
    "    word_lower_counts = Counter(dict(lower_nondeleted_items))                    \n",
    "    return word_lower_counts        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of lowercase counter after deletions: 4018\n"
     ]
    }
   ],
   "source": [
    "word_lower_counts = get_words_counter(corpus)\n",
    "print('Size of lowercase counter after deletions: {}'.format(len(word_lower_counts)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
