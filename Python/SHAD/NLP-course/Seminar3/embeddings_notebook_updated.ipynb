{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторные представления слов и предложений (семинар 26.10.17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-22T21:56:15.935187Z",
     "start_time": "2017-10-23T00:56:15.928680+03:00"
    }
   },
   "source": [
    "**Дедлайны:** 9.00 утра 5 октября (очники), 9.00 утра 8 октября (заочники).\n",
    "\n",
    "На этом семинаре мы проверим, способен ли простой подход на основе векторных представлений слов, находить вопросы-дубликаты на StackOverflow. Для этого мы подготовили для вас выборку дубликатов и выложили на страницу курса.\n",
    "\n",
    "\n",
    "**План действий:**\n",
    "\n",
    "* Скачаем предобученные вектора модели word2vec (с тем же успехом могли бы взять и вектора моделей GloVe, FastText, или любые другие).\n",
    "* Усредним вектора слов в вопросе, чтобы получить представление всего вопроса.\n",
    "* Отранжируем по вопросу-запросу набор из 100 случайных вопросов и 1 вопроса-дубликата. Будем использовать косинусную меру близости между векторами вопросов.\n",
    "* На каком месте в выдаче окажется вопрос-дубликат? Оценим качество ранжирования.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном задании понадобятся:\n",
    "- Предобученные вектора слов (GoogleNews-vectors-negative300)\n",
    "- Данные о дубликатах вопросов с stackoverflow для анализа качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка предобученных векторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T17:17:11.768588Z",
     "start_time": "2017-10-23T20:17:11.762581+03:00"
    }
   },
   "source": [
    "Скачайте предобученные вектора https://code.google.com/archive/p/word2vec/ (GoogleNews-vectors-negative300) и создайте объект в gensim: https://radimrehurek.com/gensim/models/keyedvectors.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', \n",
    "                                                             binary=True, limit=500000)\n",
    "# Your code here.\n",
    "# \n",
    "#\n",
    "#\n",
    "###################\n",
    "\n",
    "assert embeddings.most_similar(positive=['queen', 'man'], negative=['woman'], topn=1)[0][0] == 'king'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка тестового датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном задании обучать ничего не нужно, поэтому достаточно загрузить только тестовый датасет. Это список пар очищенных вопросов-дубликатов со StackOverflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T17:20:32.021786Z",
     "start_time": "2017-10-23T20:20:31.941056+03:00"
    }
   },
   "outputs": [],
   "source": [
    "def read_question_duplicates(filepath):\n",
    "    \"\"\"Reads duplicate questions from file. filename. \n",
    "    \n",
    "    Args:\n",
    "        filepath: full path the the file with duplicate questions.\n",
    "        \n",
    "    Returns:\n",
    "        questions (a list of strings): All questions from data.\n",
    "        duplicate_idxs (a list of tuples of ints): Indices for duplicate questions.\n",
    "    \"\"\"\n",
    "    \n",
    "    questions_all = []\n",
    "    duplicate_idxs = []\n",
    "    current_idx = 0\n",
    "    with open(filepath, 'r') as f:\n",
    "        for row in f.readlines():\n",
    "            questions = row.lower().strip().split(\"\\t\")\n",
    "            assert len(questions) >= 2\n",
    "            questions_all.extend(questions[:2])\n",
    "            duplicate_idxs.append((current_idx, current_idx+1))\n",
    "            current_idx += 2\n",
    "    return questions_all, duplicate_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, duplicate_idxs = read_question_duplicates('duplicate_questions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how to print a binary heap tree without recursion', 'how do you best convert a recursive function to an iterative one', 'phonestatelistener and service', 'how to start phonestatelistener programmatically', 'when hover on div1 depenting on if it is on div2 or not it should act differently', 'jquery show a div2 when mousenter over div1 is over', 'asynchronous sequence of events using promises', 'performing async method in a loop in node js and waiting for result', 'unreal engine 4 save rendered frame to memory', 'ue4 output game frames to file']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ранжирование и оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если векторные представления для текстов (вопросов из stackoverflow) получаются хорошими, то косинусное расстояние между дубликатами должно получаться меньше, чем расстояние до случайного текста.\n",
    "Поэтому для каждой пары дубликатов сгенерируем N случайных отрицательных текстов и посчитаем метрику DCG (https://en.wikipedia.org/wiki/Discounted_cumulative_gain). Будем считать, что релевантности случайных примеров равны 0, а релевантность истинного дубликата равна 1.\n",
    "\n",
    "$$\n",
    "DCG_k = \\sum_{i=1}^k \\frac{rel_i}{\\log (1 + i)}   =\\frac{1}{\\log(1+rank_{dup})} \\cdot [rank_{dup} < k],\n",
    "$$\n",
    "\n",
    "где $rank_{dup} \\in [1, k]$ - позиция дубликата в отсортированном списке близости векторных представлений. Чем она больше, тем ближе дубликат по косинусному расстоянию к запросу и тем лучше наши векторные представления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T17:29:11.889519Z",
     "start_time": "2017-10-23T20:29:11.866385+03:00"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_distance(v1, v2):\n",
    "    return 1 - np.sum(v1 * v2) / np.sqrt(np.sum(v1 * v1) * np.sum(v2 * v2))\n",
    "    \n",
    "def evaluate_dcg(object_vecs, duplicate_idxs, negative_idxs, k_values):\n",
    "    \"\"\" \n",
    "    Ranks candidates by their embeddings and evaluates the ranking by DCG metric.\n",
    "    \n",
    "    Args:\n",
    "        object_vecs (ndarray): Embeddings for all objects (questions).\n",
    "        duplicate_idxs (list([ind1, ind2])): Duplicate indices (as defined by order in object_vecs).\n",
    "        negative_idxs (list([ind_neg1, ... ind_negN])): Indices of negative objects for each duplicate pair.\n",
    "        k_values (list): Several sizes of ranked lists for computing DCG@k.\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "        dcg_values (list): Computed values of DCG_at_k for each k (averaged over examples).\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(duplicate_idxs) == len(negative_idxs)\n",
    "    \n",
    "    # List (by a number of queries) of lists (by a number of different k) of dcg_at_k values. \n",
    "    dcg_values = []\n",
    "    \n",
    "    for (duplicate_ind1, duplicate_ind2), neg_indxs in zip(duplicate_idxs, negative_idxs):\n",
    "        negative_size = len(neg_indxs)\n",
    "        repeated_query = np.repeat(duplicate_ind1, negative_size + 1)\n",
    "        candidates = np.hstack([duplicate_ind2, neg_indxs])\n",
    "        distances = np.array([cosine_distance(object_vecs[candidates[i]], \n",
    "                                              object_vecs[repeated_query[i]]) for i in range(len(candidates))])\n",
    "        rank = np.searchsorted(distances, distances[0]) + 1\n",
    "        dcg_values.append([(rank <= k).astype(int) / np.log2(1 + rank) for k in k_values])\n",
    "        \n",
    "    # Average over different queries.\n",
    "    dcg_values = np.mean(dcg_values, axis=0)\n",
    "    return dcg_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве отрицательных примеров будем брать случайные вопросы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(249)\n",
    "negative_size = 100\n",
    "random_negative_idxs = [np.random.choice([idx for idx in range(len(questions))\n",
    "                                          if idx not in di], \n",
    "                                          replace=False, \n",
    "                                          size=negative_size) for di in duplicate_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение векторных представлений вопросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ получить векторное представление вопроса - усреднить вектора его слов. Релизуйте функцию ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question2vec_mean(questions, embeddings):\n",
    "    result = np.zeros((len(questions), embeddings.vector_size))\n",
    "    for i in range(len(questions)):\n",
    "        words = questions[i].split(' ')\n",
    "        vectors = []\n",
    "        for word in words:\n",
    "            if word in embeddings:\n",
    "                vectors.append(embeddings[word])\n",
    "        result[i] = np.mean(vectors, axis=0)\n",
    "    return result \n",
    "    \"\"\" \n",
    "    Computes question embeddings by averaging word embeddings.\n",
    "    \n",
    "    Args:\n",
    "      questions (list of strings): List of questions to be embedded.\n",
    "      embeddings (gensim object): Pre-trained word embeddings.\n",
    "      \n",
    "    Returns:\n",
    "      ndarray of shape [num_questions, embed_size] with question embeddings.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "lel = np.array([embeddings['andrew'], embeddings['loh']])\n",
    "lel.shape\n",
    "print(np.mean(lel, axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "question_vecs = question2vec_mean(questions, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert question_vecs.shape[1] == 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведем оценку качества векторных представлений для вопросов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcg_values = evaluate_dcg(question_vecs, duplicate_idxs, random_negative_idxs, [1,5,10,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65331529  0.66786518  0.6763846   0.72094283]\n"
     ]
    }
   ],
   "source": [
    "print(dcg_values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T17:50:20.107237Z",
     "start_time": "2017-10-23T20:50:20.103240+03:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert dcg_values[0] > 0.44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь придумайте более продвинутый алгоритм, чтобы побить **порог 0.46 для DCG@1**. Например, можно подобрать схему взвешивания векторов слов, получше предобработать тестовые предложения, или придумать что-нибудь еще. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question2vec_advanced(questions, embeddings):\n",
    "    result = np.zeros((len(questions), embeddings.vector_size))\n",
    "    for i in range(len(questions)):\n",
    "        words = questions[i].split(' ')\n",
    "        vectors = []\n",
    "        for word in words:\n",
    "            if word in embeddings and len(word) > 2:\n",
    "                vectors.append(embeddings[word])\n",
    "        result[i] = np.mean(vectors, axis=0)\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T17:53:56.550951Z",
     "start_time": "2017-10-23T20:53:52.072831+03:00"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question_vecs = question2vec_advanced(questions, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert question_vecs.shape[1] == 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dcg_values = evaluate_dcg(question_vecs, duplicate_idxs, random_negative_idxs, [1,5,10,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-22T22:21:24.330731Z",
     "start_time": "2017-10-23T01:21:24.326665+03:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert dcg_values[0] > 0.46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом сдаваемая часть задания заканчивается, и начинается тьюториал по библиотеке Faiss для быстрого поиска ближайших соседей в нашем векторном пространстве слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial: Faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Следующий пункт не явялется обязательным, но рекомендуется для ознакомления.** Далее используется библиотека https://github.com/facebookresearch/faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки качества векторных представлений для предложений ранее, мы выбирали негативные примеры как рандомные предложения из корпуса. И так как рандомный пример скорее всего не близок к текущему (например из другого раздела на сайте stackoverflow), в среднем мы получаем хоршие значения метрики  DCG. Однако мы можем брать самые близкие примеры из корпусапо косинуснуму расстоянию, таким образом получая сильные отрицательные примеры.\n",
    "\n",
    "Если мы для каждого вектора будем считать попарные расстояния с каждым вектором из корпуса, это займет очень много времени (N^2 для всех векторов). Библиотека faiss позволяет быстро и эффективно находить k-ближайших **dense** векторов по разным метрикам (L2, косинусное расстояние и т.д). Также данная библиотека поддерживает работу на GPU.\n",
    "\n",
    "Быстро находить близкие dense-вектора полезно во многих задачах - поиск ближайших изображений, поиск кандидатов для рекомендаций и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T17:59:54.387045Z",
     "start_time": "2017-10-23T20:59:54.360713+03:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T17:59:54.822224Z",
     "start_time": "2017-10-23T20:59:54.818122+03:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T17:59:55.771229Z",
     "start_time": "2017-10-23T20:59:55.766754+03:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim = 300\n",
    "index = faiss.IndexFlatIP(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T12:14:21.792853Z",
     "start_time": "2017-10-23T15:14:21.787151+03:00"
    }
   },
   "source": [
    "Так как из коробки библиотека не нормирует вектора, нужно сначала их отнормировать, чтобы получать корректные косинусные расстояния."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_normed = question_vecs_mean_word / np.linalg.norm(question_vecs_mean_word, axis=1)[:, np.newaxis]\n",
    "question_normed = question_normed.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим вектора в индекс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T18:00:22.353279Z",
     "start_time": "2017-10-23T21:00:22.282571+03:00"
    }
   },
   "outputs": [],
   "source": [
    "index.add(question_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T18:00:50.637462Z",
     "start_time": "2017-10-23T21:00:25.075983+03:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 29s, sys: 4min 12s, total: 6min 42s\n",
      "Wall time: 25.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_neighbors = negative_size + 2\n",
    "_, neighbors_list = index.search(question_normed, n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что поиск 100 ближайших соседей для всех векторов в корпусе занял довольно мало времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее для каждой пары дубликатов найдем ближайшие отрицательные примеры как ближайшие к первому вектору."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T18:01:29.835554Z",
     "start_time": "2017-10-23T21:01:28.630252+03:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strong_negative_idxs = [[idx for idx in neighbors_list[dup_ind1] if idx not in (dup_ind1, dup_ind2)][:negative_size] \n",
    "                        for dup_ind1, dup_ind2 in duplicate_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T18:01:52.675482Z",
     "start_time": "2017-10-23T21:01:39.351351+03:00"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18475it [00:13, 1388.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@1: 0.1411637347767253\n",
      "DCG@5: 0.18647366877376192\n",
      "DCG@10: 0.1979738058932608\n",
      "DCG@100: 0.22392785361147613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_ = evaluate_dcg(question_vecs, duplicate_idxs, strong_negative_idxs, [1,5,10,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T12:18:39.327869Z",
     "start_time": "2017-10-23T15:18:39.322081+03:00"
    }
   },
   "source": [
    "Метрика DCG в данном случае получилась значительно меньше. Зато в реальных задачах часто лучше сравниваться не с рандомными примерами, а с отрицательными примерами на которых большой шанс ошибиться.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее посмотрим какие отрицательные примеры мы получаем в случае ближайших векторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T18:02:28.119766Z",
     "start_time": "2017-10-23T21:02:28.112054+03:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: 'how to print a binary heap tree without recursion'\n",
      "\n",
      "duplicate question: 'how do you best convert a recursive function to an iterative one'\n",
      "\n",
      "negative sample question 0: 'how to find the height of a node in binary tree recursively'\n",
      "negative sample question 1: 'how to delete all nodes of a binary search tree'\n",
      "negative sample question 2: 'recursion and binary trees'\n",
      "negative sample question 3: 'get all possible binary trees using prolog'\n"
     ]
    }
   ],
   "source": [
    "print(\"question: '{}'\\n\".format(questions[0]))\n",
    "print(\"duplicate question: '{}'\\n\".format(questions[1]))\n",
    "for i in range(4):      \n",
    "    print(\"negative sample question {}: '{}'\".format(i, questions[strong_negative_idxs[0][i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, в качестве отрицательных примеров мы взяли довольно похожие сообщения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "13px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
