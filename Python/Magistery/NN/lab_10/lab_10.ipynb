{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> this is a very light headed comedy about a wonderful family that has a son called <UNK> because he use to <UNK> at his food <UNK> loves to take all kinds of pictures of the people in a small <UNK> of <UNK> <UNK> and manages to get the attention of a group of photo art lovers from new york city <UNK> has a cute sister who goes simply nuts over <UNK> and is actually an <UNK> taking <UNK> of <UNK> from a bag there are scenes of men showing off the <UNK> in their <UNK> with <UNK> movements and <UNK> doing pretty much the same it is rather hard to keep your mind out of the <UNK> with this film but who cares it is only a film to give you a few laughs at a simple picture made in <UNK>\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed May 29 16:22:12 2019\n",
    "\n",
    "@author: asus\n",
    "\"\"\"\n",
    "\n",
    "# suggested by mdaoust\n",
    "# from https://stackoverflow.com/questions/42821330/restore-original-text-from-keras-s-imdb-dataset\n",
    "\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "\n",
    "NUM_WORDS = 5000 # only use top 5000 words\n",
    "INDEX_FROM = 3   # word index offset\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = keras.datasets.imdb.load_data(\n",
    "        num_words=NUM_WORDS, index_from=INDEX_FROM)\n",
    "\n",
    "word_to_id = imdb.get_word_index()\n",
    "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "word_to_id[\"<START>\"] = 1\n",
    "word_to_id[\"<UNK>\"] = 2\n",
    "id_to_word = {value:key for key, value in word_to_id.items()}\n",
    "\n",
    "review_id = 25\n",
    "print(' '.join(id_to_word[num] for num in train_x[review_id] ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 71s 3ms/step - loss: 0.4858 - acc: 0.7653 - val_loss: 0.4187 - val_acc: 0.8096\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 70s 3ms/step - loss: 0.3676 - acc: 0.8446 - val_loss: 0.3944 - val_acc: 0.8207\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 74s 3ms/step - loss: 0.3306 - acc: 0.8631 - val_loss: 0.3652 - val_acc: 0.8373\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 70s 3ms/step - loss: 0.2997 - acc: 0.8764 - val_loss: 0.3655 - val_acc: 0.8361\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 65s 3ms/step - loss: 0.2824 - acc: 0.8854 - val_loss: 0.3808 - val_acc: 0.8350\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 65s 3ms/step - loss: 0.2566 - acc: 0.8968 - val_loss: 0.3998 - val_acc: 0.8392\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 65s 3ms/step - loss: 0.2371 - acc: 0.9046 - val_loss: 0.3801 - val_acc: 0.8388\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 66s 3ms/step - loss: 0.2171 - acc: 0.9134 - val_loss: 0.4052 - val_acc: 0.8425\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 68s 3ms/step - loss: 0.1987 - acc: 0.9201 - val_loss: 0.4274 - val_acc: 0.8447\n",
      "Epoch 10/10\n",
      "24992/25000 [============================>.] - ETA: 0s - loss: 0.1839 - acc: 0.9283"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Максимальное кол-во слов (по частоте использования)\n",
    "max_features = 5000\n",
    "\n",
    "# Загружаем данные\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# Максимальная длина рецензии в словах\n",
    "maxlen = 90\n",
    "\n",
    "# Заполняем или обрезаем рецензии\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "# Создаем сеть\n",
    "model = Sequential()\n",
    "# Слой векторного представления слов\n",
    "model.add(Embedding(max_features, 48))\n",
    "model.add(keras.layers.SpatialDropout1D(0.2))\n",
    "# Слой долго-краткосрочной памяти\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "# Полносвязный слой для классификации\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Проверяем качество обучения на тестовых данных\n",
    "scores = model.evaluate(X_test, y_test, batch_size=32)\n",
    "\n",
    "print(\"Точность на тестовых данных: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "\n",
    "# Сохраняем нейронную сеть\n",
    "\n",
    "# Генерируем описание модели в формате json\n",
    "model_json = model.to_json()\n",
    "# Записываем модель в файл\n",
    "json_file = open(\"LSTM.json\", \"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()\n",
    "\n",
    "model.save_weights(\"LSTM.h5\")\n",
    "\n",
    "print (\"Сохранили Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.91412]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import hashing_trick\n",
    "from keras.models import model_from_json\n",
    "json_file = open(\"LSTM.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"LSTM.h5\")\n",
    "#  Компилируем модель\n",
    "loaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#  Загружаем рецензию для распознавания\n",
    "f=open(\"review.txt\", \"r\")\n",
    "text = f.read()\n",
    "f.close()\n",
    "\n",
    "x = hashing_trick(text, 5000, hash_function=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
    "x = np.array(x)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = sequence.pad_sequences(x, maxlen = 90)\n",
    "\n",
    "#  Запускаем распознавание\n",
    "\n",
    "prediction = loaded_model.predict(x)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0346388]]\n"
     ]
    }
   ],
   "source": [
    "f=open(\"review-Copy1.txt\", \"r\")\n",
    "text = f.read()\n",
    "f.close()\n",
    "\n",
    "x = hashing_trick(text, 5000, hash_function=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
    "x = np.array(x)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = sequence.pad_sequences(x, maxlen = 90)\n",
    "\n",
    "#  Запускаем распознавание\n",
    "\n",
    "prediction = loaded_model.predict(x)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
